# CKS Practice Exam 01 - 100å•

## ğŸ“‹ è©¦é¨“æ¦‚è¦

**åˆ¶é™æ™‚é–“**: 120åˆ†  
**å•é¡Œæ•°**: 100å•  
**åˆæ ¼ç‚¹**: 67ç‚¹ä»¥ä¸Š  
**å½¢å¼**: å®ŸæŠ€è©¦é¨“ï¼ˆkubectlæ“ä½œï¼‰

## ğŸ¯ ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥é…ç‚¹

- Cluster Setup (10%) - 10å•
- Cluster Hardening (15%) - 15å•  
- System Hardening (15%) - 15å•
- Minimize Microservice Vulnerabilities (20%) - 20å•
- Supply Chain Security (20%) - 20å•
- Monitoring, Logging and Runtime Security (20%) - 20å•

---

## ğŸ—ï¸ Domain 1: Cluster Setup (10å•)

### å•é¡Œ1 (2ç‚¹)
etcdãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æš—å·åŒ–ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„ã€‚
- æš—å·åŒ–è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: `/etc/kubernetes/encryption-config.yaml`
- ä½¿ç”¨ã™ã‚‹æš—å·åŒ–æ–¹å¼: `aescbc`
- API Serverã‚’å†èµ·å‹•ã—ã€æ—¢å­˜ã®secretã‚’å†æš—å·åŒ–ã—ã¦ãã ã•ã„

**è§£ç­”ä¾‹:**
```bash
# 1. æš—å·åŒ–è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
sudo cat > /etc/kubernetes/encryption-config.yaml << EOF
apiVersion: apiserver.config.k8s.io/v1
kind: EncryptionConfiguration
resources:
- resources:
  - secrets
  providers:
  - aescbc:
      keys:
      - name: key1
        secret: $(head -c 32 /dev/urandom | base64)
  - identity: {}
EOF

# 2. API Serverè¨­å®šæ›´æ–°
sudo vim /etc/kubernetes/manifests/kube-apiserver.yaml
# --encryption-provider-config=/etc/kubernetes/encryption-config.yaml ã‚’è¿½åŠ 

# 3. æ—¢å­˜secretã®å†æš—å·åŒ–
kubectl get secrets --all-namespaces -o json | kubectl replace -f -
```

### å•é¡Œ2 (2ç‚¹)
kubeletã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šã‚’å¼·åŒ–ã—ã¦ãã ã•ã„ã€‚
- åŒ¿åã‚¢ã‚¯ã‚»ã‚¹ã‚’ç„¡åŠ¹åŒ–
- ReadOnlyPortã‚’ç„¡åŠ¹åŒ–
- Webhookèªè¨¼ã‚’æœ‰åŠ¹åŒ–

**è§£ç­”ä¾‹:**
```bash
sudo vim /var/lib/kubelet/config.yaml
```
```yaml
authentication:
  anonymous:
    enabled: false
  webhook:
    enabled: true
authorization:
  mode: Webhook
readOnlyPort: 0
```

### å•é¡Œ3 (2ç‚¹)
API Serverã¸ã®åŒ¿åã‚¢ã‚¯ã‚»ã‚¹ã‚’å®Œå…¨ã«ç„¡åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
sudo vim /etc/kubernetes/manifests/kube-apiserver.yaml
# --anonymous-auth=false ã‚’è¿½åŠ 
```

### å•é¡Œ4 (2ç‚¹)
TLSè¨¼æ˜æ›¸ã®æœ‰åŠ¹æœŸé™ã‚’ç¢ºèªã—ã€kubeletè¨¼æ˜æ›¸ã®è‡ªå‹•ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æœ‰åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# è¨¼æ˜æ›¸ã®ç¢ºèª
sudo openssl x509 -in /etc/kubernetes/pki/apiserver.crt -text -noout | grep "Not After"

# kubeletè¨­å®šæ›´æ–°
sudo vim /var/lib/kubelet/config.yaml
# rotateCertificates: true ã‚’è¿½åŠ 
```

### å•é¡Œ5 (2ç‚¹)
Control Planeã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒé©åˆ‡ãªãƒãƒ¼ãƒˆã§å‹•ä½œã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€ä¸è¦ãªãƒãƒ¼ãƒˆã‚’é–‰ã˜ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# ãƒãƒ¼ãƒˆã®ç¢ºèª
sudo netstat -tlnp | grep -E "(6443|2379|10250)"

# firewallè¨­å®š
sudo ufw deny 10255  # kubelet read-only port
```

### å•é¡Œ6 (1ç‚¹)
API Serverã®ç›£æŸ»ãƒ­ã‚°ã‚’æœ‰åŠ¹åŒ–ã—ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¨˜éŒ²ã—ã¦ãã ã•ã„ã€‚
- ç›£æŸ»ãƒãƒªã‚·ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«: `/etc/kubernetes/audit-policy.yaml`
- ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: `/var/log/kubernetes/audit.log`

**è§£ç­”ä¾‹:**
```bash
# 1. ç›£æŸ»ãƒãƒªã‚·ãƒ¼ä½œæˆ
sudo cat > /etc/kubernetes/audit-policy.yaml << EOF
apiVersion: audit.k8s.io/v1
kind: Policy
rules:
- level: Metadata
  resources:
  - group: ""
    resources: ["secrets", "configmaps"]
- level: Request
  resources:
  - group: "rbac.authorization.k8s.io"
    resources: ["roles", "rolebindings"]
EOF

# 2. API Serverè¨­å®šæ›´æ–°
sudo vim /etc/kubernetes/manifests/kube-apiserver.yaml
# ä»¥ä¸‹ã‚’è¿½åŠ :
# --audit-log-path=/var/log/kubernetes/audit.log
# --audit-policy-file=/etc/kubernetes/audit-policy.yaml
```

### å•é¡Œ7 (1ç‚¹)
kubeletã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šã‚’å¼·åŒ–ã—ã¦ãã ã•ã„ã€‚
- Read-only portç„¡åŠ¹åŒ–
- Anonymousèªè¨¼ç„¡åŠ¹åŒ–

**è§£ç­”ä¾‹:**
```bash
# 1. kubeletè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç·¨é›†
sudo vim /var/lib/kubelet/config.yaml

# ä»¥ä¸‹ã‚’è¿½åŠ /å¤‰æ›´:
# readOnlyPort: 0
# authentication:
#   anonymous:
#     enabled: false

# 2. kubeletå†èµ·å‹•
sudo systemctl restart kubelet
```

### å•é¡Œ8 (1ç‚¹)
etcdãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«: `/opt/etcd-backup.db`

**è§£ç­”ä¾‹:**
```bash
# etcdãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
ETCDCTL_API=3 etcdctl snapshot save /opt/etcd-backup.db \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç¢ºèª
ETCDCTL_API=3 etcdctl snapshot status /opt/etcd-backup.db
```

### å•é¡Œ9 (1ç‚¹)
Control Planeã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®è¨¼æ˜æ›¸æœ‰åŠ¹æœŸé™ã‚’ç¢ºèªã—ã€æœŸé™åˆ‡ã‚Œå‰ã®è¨¼æ˜æ›¸ã‚’æ›´æ–°ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# 1. è¨¼æ˜æ›¸æœ‰åŠ¹æœŸé™ç¢ºèª
sudo kubeadm certs check-expiration

# 2. æœŸé™åˆ‡ã‚Œå‰è¨¼æ˜æ›¸ã®æ›´æ–°
sudo kubeadm certs renew all

# 3. Control Planeå†èµ·å‹•
sudo systemctl restart kubelet
```

### å•é¡Œ10 (1ç‚¹)
API Serverã®ã‚¢ãƒ‰ãƒŸãƒƒã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’è¨­å®šã—ã€ä»¥ä¸‹ã‚’æœ‰åŠ¹åŒ–ã—ã¦ãã ã•ã„ï¼š
- NodeRestriction
- PodSecurityPolicy
- ResourceQuota

**è§£ç­”ä¾‹:**
```bash
# API Serverè¨­å®šæ›´æ–°ï¼ˆ/etc/kubernetes/manifests/kube-apiserver.yamlï¼‰
# --enable-admission-plugins ã«ä»¥ä¸‹ã‚’è¿½åŠ :
# NodeRestriction,PodSecurityPolicy,ResourceQuota

# API Serverå†èµ·å‹•ç¢ºèª
kubectl get pods -n kube-system | grep kube-apiserver
```

---

## ğŸ”’ Domain 2: Cluster Hardening (15å•)

### å•é¡Œ6 (3ç‚¹)
`restricted`åå‰ç©ºé–“ã‚’ä½œæˆã—ã€ä»¥ä¸‹ã®RBACè¨­å®šã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚
- Service Account: `restricted-sa`
- Role: podã®èª­ã¿å–ã‚Šå°‚ç”¨æ¨©é™
- ä»–ã®ãƒªã‚½ãƒ¼ã‚¹ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã¯æ‹’å¦

**è§£ç­”ä¾‹:**
```bash
kubectl create namespace restricted

cat << EOF | kubectl apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: restricted-sa
  namespace: restricted
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: restricted
  name: pod-reader
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: read-pods
  namespace: restricted
subjects:
- kind: ServiceAccount
  name: restricted-sa
  namespace: restricted
roleRef:
  kind: Role
  name: pod-reader
  apiGroup: rbac.authorization.k8s.io
EOF
```

### å•é¡Œ7 (3ç‚¹)
Network Policyã‚’ä½œæˆã—ã€ä»¥ä¸‹ã®é€šä¿¡åˆ¶å¾¡ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚
- `production`åå‰ç©ºé–“å†…ã®Podã‹ã‚‰ã®Ingressãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®ã¿è¨±å¯
- Egressã¯`kube-system`åå‰ç©ºé–“ã®DNSã®ã¿è¨±å¯

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: production-network-policy
  namespace: production
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: production
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    - podSelector:
        matchLabels:
          k8s-app: kube-dns
    ports:
    - protocol: UDP
      port: 53
EOF
```

### å•é¡Œ8 (3ç‚¹)
ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®Service Accountã«å¯¾ã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã®è‡ªå‹•ãƒã‚¦ãƒ³ãƒˆã‚’ç„¡åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
kubectl patch serviceaccount default -p '{"automountServiceAccountToken": false}'
```

### å•é¡Œ9 (3ç‚¹)
ClusterRoleBindingã‚’ç¢ºèªã—ã€`system:anonymous`ã‚„`system:unauthenticated`ã¸ã®æ¨©é™ä»˜ä¸ã‚’å‰Šé™¤ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# å±é™ºãªBindingã®ç¢ºèª
kubectl get clusterrolebinding -o wide | grep -E "(system:anonymous|system:unauthenticated)"

# å‰Šé™¤ï¼ˆè©²å½“ã™ã‚‹ã‚‚ã®ãŒã‚ã‚Œã°ï¼‰
kubectl delete clusterrolebinding system:anonymous
```

### å•é¡Œ10 (3ç‚¹)
Admission Controllerã‚’è¨­å®šã—ã€SecurityContextã®è¨­å®šã‚’å¼·åˆ¶ã—ã¦ãã ã•ã„ã€‚
- `runAsNonRoot: true`
- `allowPrivilegeEscalation: false`

**è§£ç­”ä¾‹:**
```bash
# Pod Security Standardsã‚’ä½¿ç”¨
kubectl label namespace default pod-security.kubernetes.io/enforce=restricted
```

### å•é¡Œ11 (2ç‚¹)
ClusterRole `secret-reader` ã‚’ä½œæˆã—ã€`secrets` ãƒªã‚½ãƒ¼ã‚¹ã«å¯¾ã—ã¦ `get`, `list` æ¨©é™ã®ã¿ã‚’ä»˜ä¸ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
kubectl create clusterrole secret-reader --verb=get,list --resource=secrets
```

### å•é¡Œ12 (2ç‚¹)
`security-team` Service Accountã‚’ä½œæˆã—ã€å…ˆã»ã©ä½œæˆã—ãŸClusterRoleã‚’ãƒã‚¤ãƒ³ãƒ‰ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
kubectl create serviceaccount security-team
kubectl create clusterrolebinding security-team-binding \
  --clusterrole=secret-reader \
  --serviceaccount=default:security-team
```

### å•é¡Œ13 (2ç‚¹)
Network Policyã§ã€`database` namespaceå†…ã®Podã¸ã®é€šä¿¡ã‚’ `app-tier` labelã‚’æŒã¤Podã‹ã‚‰ã®ã¿è¨±å¯ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: database-access-policy
  namespace: database
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          tier: app
    ports:
    - protocol: TCP
      port: 5432
EOF
```

### å•é¡Œ14 (2ç‚¹)
PodSecurityPolicyã‚’ä½œæˆã—ã€ç‰¹æ¨©ã‚³ãƒ³ãƒ†ãƒŠã‚’ç¦æ­¢ã—ã¦ãã ã•ã„ã€‚
- privileged: false
- allowPrivilegeEscalation: false

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: restricted-psp
spec:
  privileged: false
  allowPrivilegeEscalation: false
  runAsUser:
    rule: 'MustRunAsNonRoot'
  seLinux:
    rule: 'RunAsAny'
  volumes:
  - 'configMap'
  - 'emptyDir'
  - 'projected'
  - 'secret'
  - 'downwardAPI'
  - 'persistentVolumeClaim'
EOF
```

### å•é¡Œ15 (2ç‚¹)
ImagePolicyWebhook AdmissionControllerã‚’è¨­å®šã—ã€è¨±å¯ã•ã‚ŒãŸãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‹ã‚‰ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ã¿ã‚’è¨±å¯ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# /etc/kubernetes/imagepolicy.json
cat << EOF | sudo tee /etc/kubernetes/imagepolicy.json
{
  "imagePolicy": {
    "kubeConfigFile": "/etc/kubernetes/admission_webhook.kubeconfig",
    "allowTTL": 50,
    "denyTTL": 50,
    "retryBackoff": 500,
    "defaultAllow": false
  }
}
EOF

# API Serverè¨­å®šã«è¿½åŠ 
# --enable-admission-plugins=ImagePolicyWebhook
# --admission-control-config-file=/etc/kubernetes/imagepolicy.json
```

### å•é¡Œ16 (1ç‚¹)
API ServeråŒ¿åã‚¢ã‚¯ã‚»ã‚¹ã®ãƒ­ãƒ¼ãƒ«ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç¢ºèªã—ã€ä¸è¦ãªã‚‚ã®ã‚’å‰Šé™¤ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# åŒ¿åã‚¢ã‚¯ã‚»ã‚¹ç¢ºèª
kubectl get clusterrolebinding -o wide | grep system:anonymous

# ä¸è¦ãªãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°å‰Šé™¤
kubectl delete clusterrolebinding system:discovery
```

### å•é¡Œ17 (1ç‚¹)
Kubernetes Dashboardã®ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ã‚’å¼·åŒ–ã—ã¦ãã ã•ã„ã€‚
- adminæ¨©é™ã§ã¯ãªãã€read-onlyæ¨©é™ã‚’è¨­å®š

**è§£ç­”ä¾‹:**
```bash
# read-only ServiceAccountä½œæˆ
kubectl create serviceaccount dashboard-readonly -n kubernetes-dashboard

# ClusterRoleä½œæˆ
kubectl create clusterrole dashboard-readonly --verb=get,list,watch --resource=*.*

# ClusterRoleBindingä½œæˆ
kubectl create clusterrolebinding dashboard-readonly-binding \
  --clusterrole=dashboard-readonly \
  --serviceaccount=kubernetes-dashboard:dashboard-readonly
```

### å•é¡Œ18 (1ç‚¹)
kubeletã®èªè¨¼è¨­å®šã‚’ç¢ºèªã—ã€webhookèªè¨¼ã‚’æœ‰åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# kubeletè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç·¨é›†
sudo vim /var/lib/kubelet/config.yaml

# ä»¥ä¸‹ã‚’è¿½åŠ :
# authentication:
#   webhook:
#     enabled: true
#   x509:
#     clientCAFile: /etc/kubernetes/pki/ca.crt

sudo systemctl restart kubelet
```

### å•é¡Œ19 (1ç‚¹)
Control Planeãƒãƒ¼ãƒ‰ã¸ã®sshæ¥ç¶šã‚’åˆ¶é™ã—ã€ç‰¹å®šã®IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‹ã‚‰ã®ã¿ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# UFWè¨­å®š
sudo ufw deny ssh
sudo ufw allow from 192.168.1.100 to any port 22

# ã¾ãŸã¯/etc/hosts.allow
echo "sshd: 192.168.1.100" | sudo tee -a /etc/hosts.allow
echo "sshd: ALL" | sudo tee -a /etc/hosts.deny
```

### å•é¡Œ20 (1ç‚¹)
APIã‚µãƒ¼ãƒãƒ¼ã®è¦æ±‚ç‡åˆ¶é™ï¼ˆrate limitingï¼‰ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# API Serverè¨­å®šã«ä»¥ä¸‹ã‚’è¿½åŠ 
# --max-requests-inflight=400
# --max-mutating-requests-inflight=200

# /etc/kubernetes/manifests/kube-apiserver.yaml ã‚’ç·¨é›†
```

---

## ğŸ›¡ï¸ Domain 3: System Hardening (15å•)

### å•é¡Œ21 (3ç‚¹)
AppArmorãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€nginxã‚³ãƒ³ãƒ†ãƒŠã«é©ç”¨ã—ã¦ãã ã•ã„ã€‚
- ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å: `k8s-nginx`
- `/etc/nginx/`ã¸ã®èª­ã¿å–ã‚Šã‚¢ã‚¯ã‚»ã‚¹ã®ã¿è¨±å¯
- ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®æ›¸ãè¾¼ã¿ã‚’æ‹’å¦

**è§£ç­”ä¾‹:**
```bash
# AppArmorãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
sudo cat > /etc/apparmor.d/k8s-nginx << EOF
#include <tunables/global>

/usr/sbin/nginx flags=(attach_disconnected,mediate_deleted) {
  #include <abstractions/base>
  #include <abstractions/nameservice>

  capability setuid,
  capability setgid,

  /usr/sbin/nginx mr,
  /etc/nginx/ r,
  /etc/nginx/** r,
  /var/log/nginx/ rw,
  /var/log/nginx/** rw,

  deny /etc/passwd w,
  deny /etc/shadow rwklx,
  deny /proc/sys/kernel/** wklx,
}
EOF

# ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
sudo apparmor_parser -r /etc/apparmor.d/k8s-nginx

# Podä½œæˆ
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: nginx-apparmor
  annotations:
    container.apparmor.security.beta.kubernetes.io/nginx: localhost/k8s-nginx
spec:
  containers:
  - name: nginx
    image: nginx
EOF
```

### å•é¡Œ22 (3ç‚¹)
Seccompãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€è¨±å¯ã•ã‚ŒãŸsyscallã®ã¿ã‚’å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# Seccompãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
sudo mkdir -p /var/lib/kubelet/seccomp/profiles
sudo cat > /var/lib/kubelet/seccomp/profiles/minimal.json << EOF
{
  "defaultAction": "SCMP_ACT_ERRNO",
  "architectures": ["SCMP_ARCH_X86_64"],
  "syscalls": [
    {
      "names": [
        "accept4", "arch_prctl", "bind", "brk", "close", "connect",
        "dup2", "epoll_create1", "epoll_ctl", "epoll_wait", "exit",
        "exit_group", "fchown", "fcntl", "fstat", "futex", "getdents64",
        "getpid", "getuid", "listen", "mmap", "munmap", "nanosleep",
        "openat", "poll", "read", "rt_sigaction", "rt_sigprocmask",
        "rt_sigreturn", "sendto", "set_robust_list", "setgid",
        "setgroups", "setuid", "socket", "write"
      ],
      "action": "SCMP_ACT_ALLOW"
    }
  ]
}
EOF

# Podä½œæˆ
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: secure-pod
spec:
  securityContext:
    seccompProfile:
      type: Localhost
      localhostProfile: profiles/minimal.json
  containers:
  - name: app
    image: busybox
    command: ["sleep", "3600"]
EOF
```

### å•é¡Œ23 (3ç‚¹)
ãƒãƒ¼ãƒ‰ã®Linuxã‚«ãƒ¼ãƒãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç¢ºèªã—ã€ä¸è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆã«è¿½åŠ ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# èª­ã¿è¾¼ã¿æ¸ˆã¿ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç¢ºèª
lsmod

# ä¸è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆ
sudo cat >> /etc/modprobe.d/blacklist-rare-modules.conf << EOF
blacklist dccp
blacklist sctp
blacklist rds
blacklist tipc
EOF
```

### å•é¡Œ24 (3ç‚¹)
ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®ãƒã‚¦ãƒ³ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ç¢ºèªã—ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’å¼·åŒ–ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# ç¾åœ¨ã®ãƒã‚¦ãƒ³ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ç¢ºèª
mount | grep -E "(nosuid|nodev|noexec)"

# /tmp ã‚’ secure ã«ãƒã‚¦ãƒ³ãƒˆ
sudo mount -o remount,noexec,nosuid,nodev /tmp
```

### å•é¡Œ25 (3ç‚¹)
systemdã‚µãƒ¼ãƒ“ã‚¹ã®è¨­å®šã‚’ç¢ºèªã—ã€ä¸è¦ãªã‚µãƒ¼ãƒ“ã‚¹ã‚’ç„¡åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# ã‚µãƒ¼ãƒ“ã‚¹ä¸€è¦§ç¢ºèª
systemctl list-unit-files --type=service | grep enabled

# ä¸è¦ãªã‚µãƒ¼ãƒ“ã‚¹ç„¡åŠ¹åŒ–
sudo systemctl disable bluetooth
sudo systemctl disable cups
sudo systemctl stop bluetooth
sudo systemctl stop cups
```

### å•é¡Œ26 (2ç‚¹)
ã‚«ãƒ¼ãƒãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šã—ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’å¼·åŒ–ã—ã¦ãã ã•ã„ã€‚
- IPè»¢é€ç„¡åŠ¹åŒ–
- ICMP ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆç„¡åŠ¹åŒ–

**è§£ç­”ä¾‹:**
```bash
# /etc/sysctl.conf ã«è¿½åŠ 
cat << EOF | sudo tee -a /etc/sysctl.conf
net.ipv4.ip_forward = 0
net.ipv4.conf.all.accept_redirects = 0
net.ipv4.conf.default.accept_redirects = 0
net.ipv6.conf.all.accept_redirects = 0
net.ipv6.conf.default.accept_redirects = 0
EOF

# é©ç”¨
sudo sysctl -p
```

### å•é¡Œ27 (2ç‚¹)
ãƒãƒ¼ãƒ‰ã¸ã®SSHã‚¢ã‚¯ã‚»ã‚¹ã‚’å¼·åŒ–ã—ã¦ãã ã•ã„ã€‚
- Root ãƒ­ã‚°ã‚¤ãƒ³ç„¡åŠ¹åŒ–
- ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼ç„¡åŠ¹åŒ–

**è§£ç­”ä¾‹:**
```bash
# /etc/ssh/sshd_config ç·¨é›†
sudo sed -i 's/#PermitRootLogin yes/PermitRootLogin no/' /etc/ssh/sshd_config
sudo sed -i 's/#PasswordAuthentication yes/PasswordAuthentication no/' /etc/ssh/sshd_config

# SSHå†èµ·å‹•
sudo systemctl restart sshd
```

### å•é¡Œ28 (2ç‚¹)
ãƒ•ã‚¡ã‚¤ãƒ«ã®å®Ÿè¡Œæ¨©é™ã‚’åˆ¶å¾¡ã™ã‚‹ãŸã‚ã€noexecã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ãƒã‚¦ãƒ³ãƒˆã•ã‚ŒãŸä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
sudo mkdir /tmp/secure-temp

# noexecã§ãƒã‚¦ãƒ³ãƒˆ
sudo mount -t tmpfs -o noexec,nosuid,nodev tmpfs /tmp/secure-temp

# /etc/fstab ã«æ°¸ç¶šåŒ–
echo "tmpfs /tmp/secure-temp tmpfs noexec,nosuid,nodev 0 0" | sudo tee -a /etc/fstab
```

### å•é¡Œ29 (2ç‚¹)
auditdã‚’è¨­å®šã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ã‚’ç›£è¦–ã—ã¦ãã ã•ã„ã€‚
- `/etc/kubernetes/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç›£è¦–

**è§£ç­”ä¾‹:**
```bash
# audit ãƒ«ãƒ¼ãƒ«è¿½åŠ 
sudo auditctl -w /etc/kubernetes -p war -k kubernetes-config

# æ°¸ç¶šåŒ–ï¼ˆ/etc/audit/rules.d/kubernetes.rulesï¼‰
echo "-w /etc/kubernetes -p war -k kubernetes-config" | sudo tee /etc/audit/rules.d/kubernetes.rules

# auditd å†èµ·å‹•
sudo systemctl restart auditd
```

### å•é¡Œ30 (2ç‚¹)
ä¸è¦ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚µãƒ¼ãƒ“ã‚¹ã‚’ç„¡åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚
- ä½¿ç”¨ã—ã¦ã„ãªã„ãƒãƒ¼ãƒˆã®ç¢ºèªã¨ç„¡åŠ¹åŒ–

**è§£ç­”ä¾‹:**
```bash
# ãƒãƒ¼ãƒˆç¢ºèª
sudo ss -tuln

# ä¸è¦ãªã‚µãƒ¼ãƒ“ã‚¹ç¢ºèªãƒ»åœæ­¢
sudo systemctl list-units --type=service | grep -E "(telnet|ftp|rsh)"
sudo systemctl disable telnet.socket
sudo systemctl stop telnet.socket
```

### å•é¡Œ31 (1ç‚¹)
ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®æ¨©é™ã‚’ç¢ºèªã—ã€world-writableãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# world-writableãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
sudo find / -type f -perm -002 -exec ls -l {} \; 2>/dev/null

# æ¨©é™ä¿®æ­£ä¾‹
sudo chmod o-w /path/to/file
```

### å•é¡Œ32 (1ç‚¹)
SUID/SGIDãƒ“ãƒƒãƒˆãŒè¨­å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã€ä¸è¦ãªã‚‚ã®ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# SUID/SGIDãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
sudo find / -type f \( -perm -4000 -o -perm -2000 \) -exec ls -l {} \; 2>/dev/null

# ä¸è¦ãªSUIDãƒ“ãƒƒãƒˆå‰Šé™¤
sudo chmod u-s /path/to/file
```

### å•é¡Œ33 (1ç‚¹)
ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®umaskã‚’è¨­å®šã—ã€ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ•ã‚¡ã‚¤ãƒ«æ¨©é™ã‚’ç¢ºä¿ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®umaskè¨­å®š
echo "umask 022" | sudo tee -a /etc/profile

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰è¨­å®š
echo "umask 077" >> ~/.bashrc
```

### å•é¡Œ34 (1ç‚¹)
ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¨©é™ã‚’ç¢ºèªã—ã€é©åˆ‡ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¨©é™ç¢ºèª
ls -la /var/log/

# æ¨©é™ä¿®æ­£
sudo chmod 640 /var/log/syslog
sudo chown root:adm /var/log/syslog
```

### å•é¡Œ35 (1ç‚¹)
ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã¨æ™‚åˆ»åŒæœŸã‚’ç¢ºèªã—ã€NTPã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# ç¾åœ¨ã®æ™‚åˆ»è¨­å®šç¢ºèª
timedatectl status

# NTPæœ‰åŠ¹åŒ–
sudo timedatectl set-ntp true

# ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³è¨­å®š
sudo timedatectl set-timezone Asia/Tokyo
```

---

## ğŸ” Domain 4: Minimize Microservice Vulnerabilities (20å•)

### å•é¡Œ36 (4ç‚¹)
Pod Security Standardsã‚’ä½¿ç”¨ã—ã¦ã€`baseline`ãƒ¬ãƒ™ãƒ«ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’`development`åå‰ç©ºé–“ã«é©ç”¨ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
kubectl create namespace development
kubectl label namespace development \
  pod-security.kubernetes.io/enforce=baseline \
  pod-security.kubernetes.io/audit=baseline \
  pod-security.kubernetes.io/warn=baseline
```

### å•é¡Œ37 (4ç‚¹)
OPA Gatekeeperã‚’ä½¿ç”¨ã—ã¦ã€ã™ã¹ã¦ã®Podã«ãƒªã‚½ãƒ¼ã‚¹åˆ¶é™ã‚’å¼·åˆ¶ã™ã‚‹ãƒãƒªã‚·ãƒ¼ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: templates.gatekeeper.sh/v1beta1
kind: ConstraintTemplate
metadata:
  name: resourcelimits
spec:
  crd:
    spec:
      names:
        kind: ResourceLimits
      validation:
        type: object
  targets:
    - target: admission.k8s.gatekeeper.sh
      rego: |
        package resourcelimits

        violation[{"msg": msg}] {
          container := input.review.object.spec.containers[_]
          not container.resources.limits.memory
          msg := "Container must have memory limits"
        }
        
        violation[{"msg": msg}] {
          container := input.review.object.spec.containers[_]
          not container.resources.limits.cpu
          msg := "Container must have CPU limits"
        }
---
apiVersion: constraints.gatekeeper.sh/v1beta1
kind: ResourceLimits
metadata:
  name: must-have-limits
spec:
  match:
    kinds:
      - apiGroups: [""]
        kinds: ["Pod"]
EOF
```

### å•é¡Œ38 (4ç‚¹)
Service Meshã‚’ä½¿ç”¨ã—ã¦ã€mTLSé€šä¿¡ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚ï¼ˆIstioä½¿ç”¨ï¼‰

**è§£ç­”ä¾‹:**
```bash
# Istio ã‚µã‚¤ãƒ‰ã‚«ãƒ¼æ³¨å…¥æœ‰åŠ¹åŒ–
kubectl label namespace production istio-injection=enabled

# PeerAuthenticationè¨­å®š
cat << EOF | kubectl apply -f -
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default
  namespace: production
spec:
  mtls:
    mode: STRICT
EOF
```

### å•é¡Œ39 (4ç‚¹)
å®Ÿè¡Œæ™‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’å¼·åŒ–ã™ã‚‹ãŸã‚ã€èª­ã¿å–ã‚Šå°‚ç”¨ãƒ«ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ã™ã‚‹Podã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: readonly-pod
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 2000
  containers:
  - name: app
    image: nginx
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
    volumeMounts:
    - name: tmp
      mountPath: /tmp
    - name: var-cache
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
  volumes:
  - name: tmp
    emptyDir: {}
  - name: var-cache
    emptyDir: {}
  - name: var-run
    emptyDir: {}
EOF
```

### å•é¡Œ40 (4ç‚¹)
Podã®ç‰¹æ¨©ã‚’æœ€å°åŒ–ã™ã‚‹ãŸã‚ã€ä¸è¦ãªLinux capabilityã‚’ã™ã¹ã¦å‰Šé™¤ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: minimal-privileges
spec:
  containers:
  - name: app
    image: busybox
    command: ["sleep", "3600"]
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      runAsNonRoot: true
      runAsUser: 1000
EOF
```

### å•é¡Œ41 (3ç‚¹)
ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã®ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æœ€å°åŒ–ã—ã€distrolessã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: distroless-app
spec:
  containers:
  - name: app
    image: gcr.io/distroless/java:11
    command: ["java", "-jar", "app.jar"]
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      capabilities:
        drop:
        - ALL
EOF
```

### å•é¡Œ42 (3ç‚¹)
Falcoã‚’ä½¿ç”¨ã—ã¦å®Ÿè¡Œæ™‚ã®ç•°å¸¸æ¤œçŸ¥ãƒ«ãƒ¼ãƒ«ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# Falcoãƒ«ãƒ¼ãƒ«è¨­å®š
cat << EOF > /etc/falco/falco_rules.local.yaml
- rule: Suspicious Container Activity
  desc: Detect suspicious activity in containers
  condition: spawned_process and container and proc.name in (nc, ncat, netcat)
  output: Suspicious network tool executed (user=%user.name command=%proc.cmdline container=%container.name)
  priority: WARNING
EOF

# Falcoå†èµ·å‹•
sudo systemctl restart falco
```

### å•é¡Œ43 (3ç‚¹)
NetworkPolicyã‚’ä½¿ç”¨ã—ã¦ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹é–“ã®é€šä¿¡ã‚’åˆ¶é™ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: frontend-netpol
  namespace: production
spec:
  podSelector:
    matchLabels:
      app: frontend
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    ports:
    - protocol: TCP
      port: 80
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: backend
    ports:
    - protocol: TCP
      port: 8080
  - to: []
    ports:
    - protocol: UDP
      port: 53
EOF
```

### å•é¡Œ44 (3ç‚¹)
Resource Quotaã‚’è¨­å®šã—ã€ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã®ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ã‚’åˆ¶é™ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: ResourceQuota
metadata:
  name: microservice-quota
  namespace: production
spec:
  hard:
    requests.cpu: "4"
    requests.memory: 8Gi
    limits.cpu: "8"
    limits.memory: 16Gi
    pods: "10"
    secrets: "5"
    configmaps: "5"
EOF
```

### å•é¡Œ45 (3ç‚¹)
LimitRangeã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒ³ãƒ†ãƒŠã®æœ€å°ãƒ»æœ€å¤§ãƒªã‚½ãƒ¼ã‚¹ã‚’åˆ¶å¾¡ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: LimitRange
metadata:
  name: microservice-limits
  namespace: production
spec:
  limits:
  - type: Container
    default:
      cpu: 100m
      memory: 128Mi
    defaultRequest:
      cpu: 50m
      memory: 64Mi
    min:
      cpu: 10m
      memory: 32Mi
    max:
      cpu: 500m
      memory: 512Mi
EOF
```

### å•é¡Œ46 (2ç‚¹)
ã‚³ãƒ³ãƒ†ãƒŠå†…ã§ã®ç‰¹æ¨©ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é˜²æ­¢ã™ã‚‹è¨­å®šã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: no-privilege-escalation
spec:
  containers:
  - name: app
    image: nginx:alpine
    securityContext:
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 1001
      capabilities:
        drop:
        - ALL
EOF
```

### å•é¡Œ47 (2ç‚¹)
PodDisruptionBudgetã‚’è¨­å®šã—ã€ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã®å¯ç”¨æ€§ã‚’ä¿è­·ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: frontend-pdb
  namespace: production
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: frontend
EOF
```

### å•é¡Œ48 (2ç‚¹)
ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒˆãƒ¼ã‚¯ãƒ³ã®è‡ªå‹•ãƒã‚¦ãƒ³ãƒˆã‚’ç„¡åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: secure-sa
  namespace: production
automountServiceAccountToken: false
---
apiVersion: v1
kind: Pod
metadata:
  name: secure-pod
spec:
  serviceAccountName: secure-sa
  automountServiceAccountToken: false
  containers:
  - name: app
    image: nginx:alpine
EOF
```

### å•é¡Œ49 (2ç‚¹)
initContainerã‚’ä½¿ç”¨ã—ã¦ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ãƒŠã®åˆæœŸåŒ–ã‚’å®‰å…¨ã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: secure-init-pod
spec:
  initContainers:
  - name: init-security
    image: busybox:1.35
    command: ['sh', '-c', 'echo "Security checks completed"']
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
  containers:
  - name: app
    image: nginx:alpine
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 101
      capabilities:
        drop:
        - ALL
EOF
```

### å•é¡Œ50 (2ç‚¹)
HorizontalPodAutoscalerã‚’è¨­å®šã—ã€è² è·ã«å¿œã˜ãŸã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: frontend-hpa
  namespace: production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: frontend
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
EOF
```

### å•é¡Œ51 (2ç‚¹)
ã‚»ã‚­ãƒ¥ã‚¢ãªç’°å¢ƒå¤‰æ•°ç®¡ç†ã®ãŸã‚ã€Secretã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# Secretä½œæˆ
kubectl create secret generic app-secrets \
  --from-literal=database-url="postgres://user:pass@db:5432/app" \
  --from-literal=api-key="secret-api-key-123"

# Pod ã§Secretä½¿ç”¨
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: secure-env-pod
spec:
  containers:
  - name: app
    image: nginx:alpine
    env:
    - name: DATABASE_URL
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: database-url
    - name: API_KEY
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: api-key
EOF
```

### å•é¡Œ52 (2ç‚¹)
VerticalPodAutoscalerã‚’è¨­å®šã—ã€ãƒªã‚½ãƒ¼ã‚¹æ¨å¥¨å€¤ã«åŸºã¥ãæœ€é©åŒ–ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: frontend-vpa
  namespace: production
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: frontend
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: frontend
      maxAllowed:
        cpu: 500m
        memory: 512Mi
      minAllowed:
        cpu: 50m
        memory: 64Mi
EOF
```

### å•é¡Œ53 (1ç‚¹)
Podé–“ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æš—å·åŒ–ã‚’æœ‰åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# Calico ã§WireGuardæš—å·åŒ–æœ‰åŠ¹åŒ–
calicoctl patch felixconfiguration default --patch='{"spec":{"wireguardEnabled":true}}'

# ã¾ãŸã¯ kubectl ä½¿ç”¨
kubectl patch felixconfiguration default --type merge --patch='{"spec":{"wireguardEnabled":true}}'
```

### å•é¡Œ54 (1ç‚¹)
Namespaceã«DefaultNetworkPolicyã‚’é©ç”¨ã—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ‹’å¦ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
  namespace: production
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
EOF
```

### å•é¡Œ55 (1ç‚¹)
ã‚³ãƒ³ãƒ†ãƒŠã®å®Ÿè¡Œæ™‚é–“åˆ¶é™ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: time-limited-pod
spec:
  activeDeadlineSeconds: 600  # 10åˆ†ã§å¼·åˆ¶çµ‚äº†
  containers:
  - name: app
    image: busybox
    command: ["sleep", "3600"]
    securityContext:
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 1000
EOF
```

---

## ğŸ” Domain 5: Supply Chain Security (20å•)

### å•é¡Œ56 (4ç‚¹)
Trivyã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã®è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³ã‚’å®Ÿè¡Œã—ã€HIGHä»¥ä¸Šã®è„†å¼±æ€§ãŒãªã„ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# Trivyã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin

# ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¹ã‚­ãƒ£ãƒ³
trivy image --severity HIGH,CRITICAL nginx:latest
trivy image --severity HIGH,CRITICAL --exit-code 1 nginx:latest
```

### å•é¡Œ57 (4ç‚¹)
ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‹ã‚‰ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ã¿ã‚’è¨±å¯ã™ã‚‹Admission Controllerã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: restrict-image-registries
spec:
  validationFailureAction: enforce
  background: false
  rules:
  - name: check-registry
    match:
      any:
      - resources:
          kinds:
          - Pod
    validate:
      message: "Images must be from approved registries"
      pattern:
        spec:
          containers:
          - image: "registry.company.com/*"
EOF
```

### å•é¡Œ58 (4ç‚¹)
cosignã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã«ç½²åã—ã€ç½²åæ¤œè¨¼ã‚’æœ‰åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# cosignã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
curl -O -L "https://github.com/sigstore/cosign/releases/latest/download/cosign-linux-amd64"
sudo mv cosign-linux-amd64 /usr/local/bin/cosign
sudo chmod +x /usr/local/bin/cosign

# ã‚­ãƒ¼ãƒšã‚¢ç”Ÿæˆ
cosign generate-key-pair

# ã‚¤ãƒ¡ãƒ¼ã‚¸ç½²å
cosign sign --key cosign.key registry.company.com/myapp:v1.0

# ç½²åæ¤œè¨¼ãƒãƒªã‚·ãƒ¼
cat << EOF | kubectl apply -f -
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: verify-image-signature
spec:
  validationFailureAction: enforce
  background: false
  rules:
  - name: verify-signature
    match:
      any:
      - resources:
          kinds:
          - Pod
    verifyImages:
    - imageReferences:
      - "registry.company.com/*"
      key: |-
        -----BEGIN PUBLIC KEY-----
        [å…¬é–‹éµã®å†…å®¹]
        -----END PUBLIC KEY-----
EOF
```

### å•é¡Œ59 (4ç‚¹)
Binary Authorization ã‚’è¨­å®šã—ã€ç½²åã•ã‚ŒãŸã‚¤ãƒ¡ãƒ¼ã‚¸ã®ã¿ã®ãƒ‡ãƒ—ãƒ­ã‚¤ã‚’è¨±å¯ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# Binary Authorization Policy
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: binary-authorization-policy
data:
  policy.yaml: |
    defaultAdmissionRule:
      requireAttestationsBy:
      - projects/PROJECT_ID/attestors/prod-attestor
      evaluationMode: REQUIRE_ATTESTATION
      enforcementMode: ENFORCED_BLOCK_AND_AUDIT_LOG
    clusterAdmissionRules:
      us-central1-c.prod-cluster:
        requireAttestationsBy:
        - projects/PROJECT_ID/attestors/prod-attestor
        evaluationMode: REQUIRE_ATTESTATION
        enforcementMode: ENFORCED_BLOCK_AND_AUDIT_LOG
EOF
```

### å•é¡Œ60 (4ç‚¹)
SBOMã‚’ç”Ÿæˆã—ã€ä¾å­˜é–¢ä¿‚ã®è„†å¼±æ€§ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# syftã‚’ä½¿ç”¨ã—ã¦SBOMç”Ÿæˆ
curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b /usr/local/bin

# SBOMç”Ÿæˆ
syft packages nginx:latest -o spdx-json > nginx-sbom.spdx.json

# è„†å¼±æ€§ç¢ºèª
grype nginx:latest
```

### å•é¡Œ61 (3ç‚¹)
ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ãƒ™ãƒ¼ã‚¹OSã‚’æœ€å°åŒ–ã—ã€alpine linuxãƒ™ãƒ¼ã‚¹ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: alpine-app
spec:
  containers:
  - name: app
    image: nginx:alpine
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 101
      capabilities:
        drop:
        - ALL
EOF
```

### å•é¡Œ62 (3ç‚¹)
ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¹ã‚­ãƒ£ãƒ³ã‚’CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«çµ±åˆã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# GitHub Actions ã§ã®ã‚¹ã‚­ãƒ£ãƒ³ä¾‹
cat << EOF > .github/workflows/security-scan.yml
name: Security Scan
on: [push, pull_request]
jobs:
  scan:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Build image
      run: docker build -t myapp:latest .
    - name: Run Trivy scanner
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: 'myapp:latest'
        format: 'sarif'
        output: 'trivy-results.sarif'
        severity: 'CRITICAL,HIGH'
        exit-code: '1'
EOF
```

### å•é¡Œ63 (3ç‚¹)
OPA Conftest ã‚’ä½¿ç”¨ã—ã¦Kubernetes YAMLãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒªã‚·ãƒ¼æ¤œè¨¼ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# Conftest ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
curl -L https://github.com/open-policy-agent/conftest/releases/latest/download/conftest_Linux_x86_64.tar.gz | tar xz
sudo mv conftest /usr/local/bin

# ãƒãƒªã‚·ãƒ¼ä½œæˆ
cat << EOF > policy.rego
package main

deny[msg] {
  input.kind == "Pod"
  input.spec.securityContext.runAsRoot == true
  msg := "Pod must not run as root"
}

deny[msg] {
  input.kind == "Pod"
  not input.spec.securityContext.readOnlyRootFilesystem
  msg := "Pod must have read-only root filesystem"
}
EOF

# ãƒãƒªã‚·ãƒ¼æ¤œè¨¼å®Ÿè¡Œ
conftest test --policy policy.rego pod.yaml
```

### å•é¡Œ64 (3ç‚¹)
AdmissionReviewã‚’ä½¿ç”¨ã—ã¦ã‚«ã‚¹ã‚¿ãƒ Admission Controllerã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingAdmissionWebhook
metadata:
  name: security-validator
webhooks:
- name: security.example.com
  clientConfig:
    service:
      name: security-webhook
      namespace: security
      path: "/validate"
  rules:
  - operations: ["CREATE", "UPDATE"]
    apiGroups: [""]
    apiVersions: ["v1"]
    resources: ["pods"]
  admissionReviewVersions: ["v1"]
  sideEffects: None
  failurePolicy: Fail
EOF
```

### å•é¡Œ65 (3ç‚¹)
ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¹ã‚­ãƒ£ãƒ³çµæœã‚’Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹å‡ºåŠ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
cat << EOF > scan-metrics.sh
#!/bin/bash
RESULT=\$(trivy image --format json nginx:latest)
HIGH_COUNT=\$(echo \$RESULT | jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "HIGH")] | length')
CRITICAL_COUNT=\$(echo \$RESULT | jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "CRITICAL")] | length')

cat << METRICS > /tmp/image-scan-metrics.txt
# HELP image_vulnerabilities_total Total number of vulnerabilities found
# TYPE image_vulnerabilities_total gauge
image_vulnerabilities_total{severity="high",image="nginx:latest"} \$HIGH_COUNT
image_vulnerabilities_total{severity="critical",image="nginx:latest"} \$CRITICAL_COUNT
METRICS
EOF

chmod +x scan-metrics.sh
```

### å•é¡Œ66 (3ç‚¹)
ã‚³ãƒ³ãƒ†ãƒŠãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã« Gvisor ã‚’è¨­å®šã—ã€ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ç’°å¢ƒã‚’æ§‹ç¯‰ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# gVisor ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
curl -fsSL https://gvisor.dev/archive.key | sudo gpg --dearmor -o /usr/share/keyrings/gvisor-archive-keyring.gpg
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/gvisor-archive-keyring.gpg] https://storage.googleapis.com/gvisor/releases release main" | sudo tee /etc/apt/sources.list.d/gvisor.list > /dev/null
sudo apt-get update && sudo apt-get install -y runsc

# RuntimeClass ä½œæˆ
cat << EOF | kubectl apply -f -
apiVersion: node.k8s.io/v1
kind: RuntimeClass
metadata:
  name: gvisor
handler: runsc
EOF
```

### å•é¡Œ67 (2ç‚¹)
ã‚¤ãƒ¡ãƒ¼ã‚¸ã«å«ã¾ã‚Œã‚‹æ©Ÿå¯†æƒ…å ±ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# truffleHog ã‚’ä½¿ç”¨
docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
  trufflesecurity/trufflehog:latest docker --image nginx:latest

# ã¾ãŸã¯ GitLeaks
docker run --rm -v \$(pwd):/scan zricethezav/gitleaks:latest detect --source /scan
```

### å•é¡Œ68 (2ç‚¹)
ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã®è„†å¼±æ€§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å®šæœŸæ›´æ–°ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# Trivy DB æ›´æ–°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
cat << EOF > update-trivy-db.sh
#!/bin/bash
echo "Updating Trivy vulnerability database..."
trivy --download-db-only
echo "Database update completed at \$(date)"
EOF

# Crontab ã«è¿½åŠ 
(crontab -l 2>/dev/null; echo "0 6 * * * /path/to/update-trivy-db.sh") | crontab -
```

### å•é¡Œ69 (2ç‚¹)
ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒãƒªã‚·ãƒ¼ã§ã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’åˆ¶é™ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: registry-access-policy
  namespace: production
spec:
  podSelector: {}
  policyTypes:
  - Egress
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: UDP
      port: 53
  - to: []
    ports:
    - protocol: TCP
      port: 443
    - protocol: TCP
      port: 80
    # æ‰¿èªã•ã‚ŒãŸãƒ¬ã‚¸ã‚¹ãƒˆãƒªã®ã¿
    namespaceSelector:
      matchLabels:
        registry: "approved"
EOF
```

### å•é¡Œ70 (2ç‚¹)
ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¬ã‚¸ã‚¹ãƒˆãƒªã¸ã®èªè¨¼æƒ…å ±ã‚’å®‰å…¨ã«ç®¡ç†ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# Docker registry secret ä½œæˆ
kubectl create secret docker-registry registry-secret \
  --docker-server=registry.company.com \
  --docker-username=user \
  --docker-password=password \
  --docker-email=user@company.com

# Pod ã§Secretä½¿ç”¨
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: private-registry-pod
spec:
  imagePullSecrets:
  - name: registry-secret
  containers:
  - name: app
    image: registry.company.com/private-app:latest
EOF
```

### å•é¡Œ71 (2ç‚¹)
ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# syft ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æƒ…å ±å–å¾—
syft packages nginx:latest -o json | jq '.artifacts[] | select(.licenses != null) | {name: .name, licenses: .licenses}'

# ã¾ãŸã¯ Tern ã‚’ä½¿ç”¨
docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
  ternd/tern:latest report -i nginx:latest
```

### å•é¡Œ72 (2ç‚¹)
ãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚µã‚¤ã‚ºã‚’æœ€å°åŒ–ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```dockerfile
# Dockerfileä¾‹
FROM golang:1.19-alpine AS builder
WORKDIR /app
COPY . .
RUN go build -o main .

FROM gcr.io/distroless/static:nonroot
WORKDIR /
COPY --from=builder /app/main .
USER 65532:65532
ENTRYPOINT ["./main"]
```

### å•é¡Œ73 (1ç‚¹)
.dockerignore ã‚’è¨­å®šã—ã¦ä¸è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ¡ãƒ¼ã‚¸çµ„ã¿è¾¼ã¿ã‚’é˜²æ­¢ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF > .dockerignore
.git
.gitignore
README.md
Dockerfile
.dockerignore
node_modules
npm-debug.log
.env
*.md
.DS_Store
EOF
```

### å•é¡Œ74 (1ç‚¹)
ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¹ã‚­ãƒ£ãƒ³çµæœã‚’ JSON å½¢å¼ã§å‡ºåŠ›ã—ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# é«˜å±é™ºåº¦ã®è„†å¼±æ€§ã®ã¿è¡¨ç¤º
trivy image --format json nginx:latest | jq '.Results[] | .Vulnerabilities[] | select(.Severity == "HIGH" or .Severity == "CRITICAL") | {ID: .VulnerabilityID, Severity: .Severity, Package: .PkgName}'
```

### å•é¡Œ75 (1ç‚¹)
ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã®ä½œæˆè€…æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# ã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç¢ºèª
docker inspect nginx:latest | jq '.[0].Config.Labels'

# ã¾ãŸã¯ Cosign ã§ã® attestation ç¢ºèª
cosign verify-attestation --key cosign.pub nginx:latest
```

---

## ğŸ” Domain 6: Monitoring, Logging and Runtime Security (20å•)

### å•é¡Œ26 (4ç‚¹)
Falcoã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€ã‚«ã‚¹ã‚¿ãƒ ãƒ«ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¦ä¸å¯©ãªãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œã‚’æ¤œå‡ºã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# Falcoã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
curl -s https://falco.org/repo/falcosecurity-3672BA8F.asc | apt-key add -
echo "deb https://download.falco.org/packages/deb stable main" | tee -a /etc/apt/sources.list.d/falcosecurity.list
apt-get update -y
apt-get install -y falco

# ã‚«ã‚¹ã‚¿ãƒ ãƒ«ãƒ¼ãƒ«ä½œæˆ
cat >> /etc/falco/falco_rules.local.yaml << EOF
- rule: Suspicious Shell Activity
  desc: Detect shell activity in containers
  condition: >
    spawned_process and
    container and
    proc.name in (sh, bash, zsh) and
    not proc.pname in (kubelet, dockerd)
  output: >
    Shell spawned in container (user=%user.name container_id=%container.id 
    container_name=%container.name shell=%proc.name parent=%proc.pname)
  priority: WARNING
  tags: [shell, container]
EOF

# Falcoèµ·å‹•
systemctl enable falco
systemctl start falco
```

### å•é¡Œ27 (4ç‚¹)
Audit loggingã‚’è¨­å®šã—ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é–¢é€£ã®APIå‘¼ã³å‡ºã—ã‚’è¨˜éŒ²ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# Audit Policyä½œæˆ
cat > /etc/kubernetes/audit-policy.yaml << EOF
apiVersion: audit.k8s.io/v1
kind: Policy
rules:
- level: RequestResponse
  resources:
  - group: ""
    resources: ["secrets", "configmaps"]
- level: Request
  resources:
  - group: ""
    resources: ["pods", "services"]
  verbs: ["create", "update", "delete"]
- level: Metadata
  resources:
  - group: "rbac.authorization.k8s.io"
    resources: ["roles", "rolebindings", "clusterroles", "clusterrolebindings"]
EOF

# API Serverè¨­å®šæ›´æ–°
vim /etc/kubernetes/manifests/kube-apiserver.yaml
# ä»¥ä¸‹ã‚’è¿½åŠ ï¼š
# --audit-log-path=/var/log/audit.log
# --audit-policy-file=/etc/kubernetes/audit-policy.yaml
```

### å•é¡Œ28 (4ç‚¹)
Runtime security monitoring ã®ãŸã‚ã€ä¸æ­£ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ã‚’æ¤œå‡ºã™ã‚‹ãƒ«ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat >> /etc/falco/falco_rules.local.yaml << EOF
- rule: Sensitive File Access
  desc: Detect access to sensitive files
  condition: >
    open_read and
    container and
    fd.name in (/etc/passwd, /etc/shadow, /etc/ssh/sshd_config, /root/.ssh/authorized_keys)
  output: >
    Sensitive file accessed (user=%user.name container_id=%container.id 
    file=%fd.name proc=%proc.name cmdline=%proc.cmdline)
  priority: HIGH
  tags: [filesystem, sensitive]
EOF
```

### å•é¡Œ29 (4ç‚¹)
ã‚³ãƒ³ãƒ†ãƒŠã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€šä¿¡ã‚’ç›£è¦–ã—ã€ç•°å¸¸ãªé€šä¿¡ã‚’æ¤œå‡ºã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat >> /etc/falco/falco_rules.local.yaml << EOF
- rule: Unexpected Outbound Connection
  desc: Detect unexpected outbound connections
  condition: >
    outbound and
    container and
    not proc.name in (curl, wget, apt, yum) and
    fd.sip.name != "127.0.0.1" and
    not fd.sport in (80, 443, 53)
  output: >
    Unexpected outbound connection (container=%container.name dest=%fd.rip:%fd.rport 
    proc=%proc.name cmdline=%proc.cmdline)
  priority: WARNING
  tags: [network, outbound]
EOF
```

### å•é¡Œ76 (4ç‚¹)
Intrusion detection ã®ãŸã‚ã€æ¨©é™æ˜‡æ ¼ã®è©¦è¡Œã‚’æ¤œå‡ºã™ã‚‹ãƒ«ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat >> /etc/falco/falco_rules.local.yaml << EOF
- rule: Privilege Escalation Attempt
  desc: Detect privilege escalation attempts
  condition: >
    spawned_process and
    container and
    proc.name in (sudo, su, passwd, chsh, chfn, chage) and
    not user.name in (root)
  output: >
    Privilege escalation attempt (user=%user.name container_id=%container.id 
    proc=%proc.name cmdline=%proc.cmdline)
  priority: CRITICAL
  tags: [privilege_escalation]
EOF
```

### å•é¡Œ77 (4ç‚¹)
Fluent Bitã‚’ä½¿ç”¨ã—ã¦Kubernetesã®ãƒ­ã‚°ã‚’é›†ç´„ã—ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# Fluent Bitè¨­å®š
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
  namespace: kube-system
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     info
        Daemon        off
        Parsers_File  parsers.conf
    
    [INPUT]
        Name              tail
        Path              /var/log/audit/audit.log
        Parser            audit
        Tag               audit.*
        Refresh_Interval  5
    
    [FILTER]
        Name    grep
        Match   audit.*
        Regex   verb (create|update|delete)
    
    [OUTPUT]
        Name  es
        Match audit.*
        Host  elasticsearch.logging.svc.cluster.local
        Port  9200
        Index security-audit
  
  parsers.conf: |
    [PARSER]
        Name   audit
        Format json
        Time_Key timestamp
        Time_Format %Y-%m-%dT%H:%M:%S.%LZ
EOF

# DaemonSetä½œæˆ
cat << EOF | kubectl apply -f -
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluent-bit
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: fluent-bit
  template:
    metadata:
      labels:
        name: fluent-bit
    spec:
      serviceAccountName: fluent-bit
      containers:
      - name: fluent-bit
        image: fluent/fluent-bit:2.0
        volumeMounts:
        - name: config
          mountPath: /fluent-bit/etc/
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
      volumes:
      - name: config
        configMap:
          name: fluent-bit-config
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
EOF
```

### å•é¡Œ78 (4ç‚¹)
Prometheusã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¦ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ç•°å¸¸ã‚’æ¤œçŸ¥ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: security-alerts
  namespace: monitoring
data:
  security-rules.yaml: |
    groups:
    - name: security.rules
      rules:
      - alert: HighFailedLogins
        expr: rate(login_failures_total[5m]) > 10
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High failed login rate detected"
          description: "{{ $value }} failed logins per second"
      
      - alert: SuspiciousAPICall
        expr: rate(apiserver_audit_requests_total{verb="delete",objectRef_resource="secrets"}[5m]) > 1
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Suspicious secret deletion detected"
          description: "Secrets being deleted at {{ $value }} per second"
      
      - alert: ContainerRootExecution
        expr: container_processes{user="root"} > 0
        for: 0m
        labels:
          severity: high
        annotations:
          summary: "Container running as root user"
          description: "Pod {{ $labels.pod }} running as root"
EOF
```

### é—®é¢˜79 (4ç‚¹)
OpenTelemetryã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ã‚’è¨­å®šã—ã¦åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã§ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¿½è·¡ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# OpenTelemetry Collectorè¨­å®š
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-config
  namespace: security
data:
  config.yaml: |
    receivers:
      jaeger:
        protocols:
          grpc:
            endpoint: 0.0.0.0:14250
          thrift_http:
            endpoint: 0.0.0.0:14268
      zipkin:
        endpoint: 0.0.0.0:9411
    
    processors:
      attributes:
        actions:
          - key: security.event
            action: insert
            value: "authentication"
      filter:
        spans:
          include:
            attributes:
              - key: "security.level"
                value: "high"
    
    exporters:
      jaeger:
        endpoint: jaeger-collector.security.svc.cluster.local:14250
        tls:
          insecure: true
      logging:
        loglevel: debug
    
    service:
      pipelines:
        traces:
          receivers: [jaeger, zipkin]
          processors: [attributes, filter]
          exporters: [jaeger, logging]
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector
  namespace: security
spec:
  replicas: 1
  selector:
    matchLabels:
      app: otel-collector
  template:
    metadata:
      labels:
        app: otel-collector
    spec:
      containers:
      - name: otel-collector
        image: otel/opentelemetry-collector:latest
        args: ["--config=/etc/otel-collector-config/config.yaml"]
        volumeMounts:
        - name: config
          mountPath: /etc/otel-collector-config
      volumes:
      - name: config
        configMap:
          name: otel-collector-config
EOF
```

### å•é¡Œ80 (3ç‚¹)
Grafanaãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¦ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å¯è¦–åŒ–ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: security-dashboard
  namespace: monitoring
data:
  security-dashboard.json: |
    {
      "dashboard": {
        "title": "Kubernetes Security Dashboard",
        "panels": [
          {
            "title": "Failed Authentication Attempts",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(authentication_attempts_total{result=\"failure\"}[5m])",
                "legendFormat": "{{method}} failures"
              }
            ]
          },
          {
            "title": "Pod Security Policy Violations",
            "type": "stat",
            "targets": [
              {
                "expr": "increase(psp_violations_total[1h])",
                "legendFormat": "PSP Violations"
              }
            ]
          },
          {
            "title": "Network Policy Denials",
            "type": "heatmap",
            "targets": [
              {
                "expr": "rate(network_policy_denials_total[5m])",
                "legendFormat": "{{namespace}}"
              }
            ]
          }
        ]
      }
    }
EOF
```

### å•é¡Œ81 (3ç‚¹)
Elasticsearchã¨Kibanaã‚’ä½¿ç”¨ã—ã¦ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°ã®æ¤œç´¢ãƒ»åˆ†æç’°å¢ƒã‚’æ§‹ç¯‰ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# Elasticsearchè¨­å®š
cat << EOF | kubectl apply -f -
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch
  namespace: logging
spec:
  serviceName: elasticsearch
  replicas: 1
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
        ports:
        - containerPort: 9200
        - containerPort: 9300
        env:
        - name: discovery.type
          value: single-node
        - name: ES_JAVA_OPTS
          value: "-Xms512m -Xmx512m"
        - name: xpack.security.enabled
          value: "true"
        - name: ELASTIC_PASSWORD
          value: "changeme"
        volumeMounts:
        - name: data
          mountPath: /usr/share/elasticsearch/data
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
---
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch
  namespace: logging
spec:
  selector:
    app: elasticsearch
  ports:
  - port: 9200
    targetPort: 9200
EOF

# Kibanaè¨­å®š
cat << EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kibana
  namespace: logging
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kibana
  template:
    metadata:
      labels:
        app: kibana
    spec:
      containers:
      - name: kibana
        image: docker.elastic.co/kibana/kibana:7.17.0
        ports:
        - containerPort: 5601
        env:
        - name: ELASTICSEARCH_HOSTS
          value: "http://elasticsearch:9200"
        - name: ELASTICSEARCH_USERNAME
          value: "elastic"
        - name: ELASTICSEARCH_PASSWORD
          value: "changeme"
EOF
```

### é—®é¢˜82 (3ç‚¹)
SIEMãƒ„ãƒ¼ãƒ«ï¼ˆSecurity Information and Event Managementï¼‰ã®ãƒ«ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# Elasticsearchã‚¯ã‚¨ãƒªãƒ«ãƒ¼ãƒ«
cat << EOF > siem-rules.json
{
  "rules": [
    {
      "name": "Multiple Failed Logins",
      "query": {
        "bool": {
          "must": [
            {"match": {"event.action": "authentication"}},
            {"match": {"event.outcome": "failure"}},
            {"range": {"@timestamp": {"gte": "now-5m"}}}
          ]
        }
      },
      "threshold": 5,
      "actions": [
        {
          "type": "webhook",
          "url": "http://alertmanager:9093/api/v1/alerts"
        }
      ]
    },
    {
      "name": "Privilege Escalation",
      "query": {
        "bool": {
          "must": [
            {"match": {"process.name": "sudo"}},
            {"match": {"container.id": "*"}},
            {"range": {"@timestamp": {"gte": "now-1m"}}}
          ]
        }
      },
      "threshold": 1,
      "priority": "high"
    }
  ]
}
EOF

# ãƒ«ãƒ¼ãƒ«é©ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
cat << EOF > apply-siem-rules.sh
#!/bin/bash
curl -X POST "elasticsearch:9200/_watcher/watch/security-alerts" \
  -H 'Content-Type: application/json' \
  -d @siem-rules.json
EOF
```

### å•é¡Œ83 (3ç‚¹)
ä¸å¯©ãªãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ¤œå‡ºã™ã‚‹ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# Falco + Sidekickè¨­å®š
cat << EOF | kubectl apply -f -
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: falco-sidekick
  namespace: falco
spec:
  selector:
    matchLabels:
      app: falco-sidekick
  template:
    metadata:
      labels:
        app: falco-sidekick
    spec:
      containers:
      - name: falco-sidekick
        image: falcosecurity/falcosidekick:latest
        env:
        - name: SLACK_WEBHOOKURL
          value: "https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"
        - name: ELASTICSEARCH_HOSTPORT
          value: "elasticsearch.logging:9200"
        - name: LOKI_HOSTPORT
          value: "http://loki.logging:3100"
        ports:
        - containerPort: 2801
---
apiVersion: v1
kind: Service
metadata:
  name: falco-sidekick
  namespace: falco
spec:
  selector:
    app: falco-sidekick
  ports:
  - port: 2801
    targetPort: 2801
EOF

# Falcoè¨­å®šæ›´æ–°
cat >> /etc/falco/falco.yaml << EOF
json_output: true
json_include_output_property: true
http_output:
  enabled: true
  url: "http://falco-sidekick.falco:2801/"
EOF
```

### å•é¡Œ84 (3ç‚¹)
Jaegerã‚’ä½¿ç”¨ã—ã¦ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹é–“ã®é€šä¿¡ã‚’ãƒˆãƒ¬ãƒ¼ã‚¹ã—ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç•°å¸¸ã‚’æ¤œå‡ºã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# Jaeger Operatorè¨­å®š
cat << EOF | kubectl apply -f -
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: security-jaeger
  namespace: observability
spec:
  strategy: production
  storage:
    type: elasticsearch
    elasticsearch:
      nodeCount: 1
      resources:
        requests:
          memory: "2Gi"
          cpu: "500m"
        limits:
          memory: "2Gi"
  collector:
    resources:
      requests:
        memory: "100Mi"
        cpu: "100m"
  query:
    resources:
      requests:
        memory: "100Mi"
        cpu: "100m"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: jaeger-security-config
  namespace: observability
data:
  config.yaml: |
    processors:
      - name: security-attributes
        config:
          rules:
            - name: detect-suspicious-calls
              condition: 'span.tags["http.status_code"] >= 400'
              action: 
                type: tag
                key: security.alert
                value: suspicious_http_error
EOF
```

### å•é¡Œ85 (3ç‚¹)
ãƒ­ã‚°ç›¸é–¢åˆ†æã‚’å®Ÿè£…ã—ã¦æ”»æ’ƒãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# Logstashè¨­å®š
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-config
  namespace: logging
data:
  logstash.conf: |
    input {
      beats {
        port => 5044
      }
    }
    
    filter {
      if [kubernetes][container][name] == "nginx" {
        grok {
          match => { "message" => "%{COMBINEDAPACHELOG}" }
        }
        
        # æ”»æ’ƒãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        if [response] >= 400 {
          mutate {
            add_tag => ["http_error"]
          }
        }
        
        # SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³æ¤œå‡º
        if [request] =~ /union|select|insert|delete|drop/i {
          mutate {
            add_tag => ["sql_injection_attempt"]
            add_field => { "security_alert" => "sql_injection" }
          }
        }
        
        # XSSæ¤œå‡º
        if [request] =~ /<script|javascript:|onload=|onerror=/i {
          mutate {
            add_tag => ["xss_attempt"]
            add_field => { "security_alert" => "xss" }
          }
        }
      }
      
      # ç›¸é–¢åˆ†æ - åŒä¸€IPã‹ã‚‰ã®å¤§é‡ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
      aggregate {
        task_id => "%{clientip}"
        code => "
          map['request_count'] ||= 0
          map['request_count'] += 1
          if map['request_count'] > 100
            event.set('security_alert', 'rate_limit_exceeded')
            event.set('alert_level', 'high')
          end
        "
        push_map_as_event_on_timeout => true
        timeout_task_id_field => "clientip"
        timeout => 300
      }
    }
    
    output {
      if [security_alert] {
        elasticsearch {
          hosts => ["elasticsearch:9200"]
          index => "security-alerts-%{+YYYY.MM.dd}"
        }
        
        http {
          url => "http://alertmanager:9093/api/v1/alerts"
          http_method => "post"
          content_type => "application/json"
          format => "json"
        }
      }
      
      elasticsearch {
        hosts => ["elasticsearch:9200"]
        index => "kubernetes-logs-%{+YYYY.MM.dd}"
      }
    }
EOF
EOF
```

### å•é¡Œ86 (2ç‚¹)
ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œã®è‡ªå‹•åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << 'EOF' > incident-response.sh
#!/bin/bash

# ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œè‡ªå‹•åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ALERT_TYPE=$1
NAMESPACE=$2
POD_NAME=$3

case $ALERT_TYPE in
  "malicious_process")
    echo "Malicious process detected in pod $POD_NAME"
    
    # Pod isolation
    kubectl label pod $POD_NAME -n $NAMESPACE security.incident=true
    kubectl annotate pod $POD_NAME -n $NAMESPACE incident.timestamp=$(date -Iseconds)
    
    # Network isolation
    cat << EOFNP | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: isolate-${POD_NAME}
  namespace: $NAMESPACE
spec:
  podSelector:
    matchLabels:
      security.incident: "true"
  policyTypes:
  - Ingress
  - Egress
EOFNP
    
    # Memory dump
    kubectl exec -n $NAMESPACE $POD_NAME -- cat /proc/1/maps > /tmp/${POD_NAME}-memory-map.txt
    
    # Log collection
    kubectl logs -n $NAMESPACE $POD_NAME > /tmp/${POD_NAME}-logs.txt
    ;;
    
  "privilege_escalation")
    echo "Privilege escalation detected"
    
    # Immediate pod termination
    kubectl delete pod $POD_NAME -n $NAMESPACE --grace-period=0 --force
    
    # Audit log collection
    grep -A 10 -B 10 $POD_NAME /var/log/audit/audit.log > /tmp/audit-${POD_NAME}.log
    
    # Alert team
    curl -X POST -H 'Content-Type: application/json' \
      -d '{"text":"CRITICAL: Privilege escalation in pod '$POD_NAME'"}' \
      $SLACK_WEBHOOK_URL
    ;;
esac

# Store evidence
tar -czf /tmp/incident-$(date +%Y%m%d-%H%M%S).tar.gz /tmp/${POD_NAME}*

echo "Incident response completed for $ALERT_TYPE"
EOF

chmod +x incident-response.sh
```

### å•é¡Œ87 (2ç‚¹)
æš—å·åŒ–ã•ã‚ŒãŸãƒ­ã‚°ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# æš—å·åŒ–ã‚­ãƒ¼ç”Ÿæˆ
kubectl create secret generic log-encryption-key \
  --from-literal=key=$(openssl rand -base64 32) \
  -n logging

# Fluent Bit æš—å·åŒ–è¨­å®š
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-encryption
  namespace: logging
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     info
        Parsers_File  parsers.conf
    
    [INPUT]
        Name              tail
        Path              /var/log/containers/*.log
        Parser            cri
        Tag               kube.*
        Refresh_Interval  5
    
    [FILTER]
        Name    lua
        Match   kube.*
        Script  encrypt.lua
        Call    encrypt_log
    
    [OUTPUT]
        Name  s3
        Match kube.*
        bucket security-logs-encrypted
        region us-west-2
        use_put_object On
        compression gzip
  
  encrypt.lua: |
    function encrypt_log(tag, timestamp, record)
        local json = require "json"
        local log_string = json.encode(record)
        
        -- å®Ÿéš›ã®æš—å·åŒ–å‡¦ç†ï¼ˆç°¡ç•¥åŒ–ï¼‰
        record["encrypted_payload"] = log_string
        record["encryption_version"] = "v1"
        
        return 1, timestamp, record
    end
  
  parsers.conf: |
    [PARSER]
        Name        cri
        Format      regex
        Regex       ^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<message>.*)$
        Time_Key    time
        Time_Format %Y-%m-%dT%H:%M:%S.%L%z
EOF
```

### å•é¡Œ88 (2ç‚¹)
ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ç›£æŸ»ã®ãŸã‚ã®ãƒ­ã‚°ä¿æŒãƒãƒªã‚·ãƒ¼ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# ILM (Index Lifecycle Management) ãƒãƒªã‚·ãƒ¼
cat << EOF > audit-log-policy.json
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "10gb",
            "max_age": "7d"
          }
        }
      },
      "warm": {
        "min_age": "7d",
        "actions": {
          "shrink": {
            "number_of_shards": 1
          },
          "allocate": {
            "number_of_replicas": 0
          }
        }
      },
      "cold": {
        "min_age": "30d",
        "actions": {
          "allocate": {
            "number_of_replicas": 0
          }
        }
      },
      "delete": {
        "min_age": "2555d"
      }
    }
  }
}
EOF

# ãƒãƒªã‚·ãƒ¼é©ç”¨
curl -X PUT "elasticsearch:9200/_ilm/policy/audit-log-policy" \
  -H 'Content-Type: application/json' \
  -d @audit-log-policy.json

# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ
curl -X PUT "elasticsearch:9200/_index_template/audit-logs" \
  -H 'Content-Type: application/json' \
  -d '{
    "index_patterns": ["audit-logs-*"],
    "template": {
      "settings": {
        "index.lifecycle.name": "audit-log-policy",
        "index.lifecycle.rollover_alias": "audit-logs"
      }
    }
  }'
```

### å•é¡Œ89 (2ç‚¹)
ç•°å¸¸æ¤œçŸ¥ã®ãŸã‚ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# Elasticsearch Machine Learningè¨­å®š
cat << EOF > ml-anomaly-detection.json
{
  "job_id": "security-anomaly-detection",
  "description": "Detect anomalies in security events",
  "analysis_config": {
    "bucket_span": "15m",
    "detectors": [
      {
        "function": "high_count",
        "field_name": "user.name",
        "detector_description": "High user activity"
      },
      {
        "function": "rare",
        "field_name": "process.name",
        "detector_description": "Rare process execution"
      },
      {
        "function": "high_mean",
        "field_name": "network.bytes",
        "by_field_name": "source.ip",
        "detector_description": "High network traffic by IP"
      }
    ]
  },
  "data_description": {
    "time_field": "@timestamp",
    "time_format": "epoch_ms"
  },
  "model_snapshot_retention_days": 7,
  "results_index_name": "security-ml-anomalies"
}
EOF

# ML Jobä½œæˆ
curl -X PUT "elasticsearch:9200/_ml/anomaly_detectors/security-anomaly-detection" \
  -H 'Content-Type: application/json' \
  -d @ml-anomaly-detection.json

# Datafeedè¨­å®š
cat << EOF > ml-datafeed.json
{
  "datafeed_id": "security-events-feed",
  "job_id": "security-anomaly-detection",
  "indices": ["security-events-*"],
  "query": {
    "bool": {
      "must": [
        {
          "range": {
            "@timestamp": {
              "gte": "now-1h"
            }
          }
        }
      ]
    }
  }
}
EOF

curl -X PUT "elasticsearch:9200/_ml/datafeeds/security-events-feed" \
  -H 'Content-Type: application/json' \
  -d @ml-datafeed.json
```

### å•é¡Œ90 (2ç‚¹)
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# Grafana Dashboardè¨­å®š
cat << EOF > realtime-security-dashboard.json
{
  "dashboard": {
    "title": "Real-time Security Dashboard",
    "refresh": "5s",
    "time": {
      "from": "now-15m",
      "to": "now"
    },
    "panels": [
      {
        "title": "Active Security Threats",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(security_events_total{severity=\"critical\"}[1m]))",
            "legendFormat": "Critical Threats"
          }
        ],
        "fieldConfig": {
          "overrides": [
            {
              "matcher": {
                "id": "byName",
                "options": "Critical Threats"
              },
              "properties": [
                {
                  "id": "color",
                  "value": {
                    "mode": "thresholds"
                  }
                },
                {
                  "id": "thresholds",
                  "value": {
                    "steps": [
                      {"color": "green", "value": null},
                      {"color": "yellow", "value": 1},
                      {"color": "red", "value": 5}
                    ]
                  }
                }
              ]
            }
          ]
        }
      },
      {
        "title": "Failed Authentication Attempts",
        "type": "timeseries",
        "targets": [
          {
            "expr": "rate(authentication_failures_total[1m])",
            "legendFormat": "{{method}} - {{namespace}}"
          }
        ]
      },
      {
        "title": "Network Policy Violations",
        "type": "bargauge",
        "targets": [
          {
            "expr": "topk(10, sum by (namespace) (rate(network_policy_violations_total[5m])))",
            "legendFormat": "{{namespace}}"
          }
        ]
      },
      {
        "title": "Pod Security Policy Violations",
        "type": "table",
        "targets": [
          {
            "expr": "sum by (pod, namespace, violation_type) (increase(psp_violations_total[1h]))",
            "format": "table"
          }
        ]
      }
    ]
  }
}
EOF

# Dashboard import
curl -X POST "http://grafana:3000/api/dashboards/db" \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer YOUR_API_KEY' \
  -d @realtime-security-dashboard.json
```

### å•é¡Œ91 (2ç‚¹)
ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è‡ªå‹•ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# AlertManagerè¨­å®š
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: monitoring
data:
  alertmanager.yml: |
    global:
      slack_api_url: 'YOUR_SLACK_WEBHOOK_URL'
    
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'security-team'
      routes:
      - match:
          severity: critical
        receiver: 'security-critical'
      - match:
          alertname: PodSecurityPolicyViolation
        receiver: 'security-psp'
    
    receivers:
    - name: 'security-team'
      slack_configs:
      - channel: '#security-alerts'
        title: 'Security Alert'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
    
    - name: 'security-critical'
      slack_configs:
      - channel: '#security-critical'
        title: 'CRITICAL Security Alert'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
        send_resolved: true
      pagerduty_configs:
      - service_key: 'YOUR_PAGERDUTY_KEY'
    
    - name: 'security-psp'
      webhook_configs:
      - url: 'http://security-automation:8080/psp-violation'
        send_resolved: false
EOF

# Prometheus Rule
cat << EOF | kubectl apply -f -
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: security-alerts
  namespace: monitoring
spec:
  groups:
  - name: security.rules
    rules:
    - alert: CriticalSecurityViolation
      expr: increase(security_violations_total{severity="critical"}[5m]) > 0
      for: 0m
      labels:
        severity: critical
      annotations:
        summary: "Critical security violation detected"
        description: "{{ $value }} critical security violations in the last 5 minutes"
    
    - alert: SuspiciousNetworkActivity
      expr: rate(network_bytes_total[5m]) > 1000000000
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "Suspicious network activity detected"
        description: "High network traffic: {{ $value }} bytes/sec"
EOF
```

### å•é¡Œ92 (1ç‚¹)
ãƒ­ã‚°ã®æ”¹ã–ã‚“æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# ãƒ­ã‚°ãƒãƒƒã‚·ãƒ¥ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
cat << 'EOF' > log-integrity-check.sh
#!/bin/bash

LOG_FILE=$1
HASH_FILE="${LOG_FILE}.sha256"

# ç¾åœ¨ã®ãƒãƒƒã‚·ãƒ¥è¨ˆç®—
CURRENT_HASH=$(sha256sum "$LOG_FILE" | cut -d' ' -f1)

# å‰å›ã®ãƒãƒƒã‚·ãƒ¥ç¢ºèª
if [ -f "$HASH_FILE" ]; then
  PREVIOUS_HASH=$(cat "$HASH_FILE")
  if [ "$CURRENT_HASH" != "$PREVIOUS_HASH" ]; then
    echo "WARNING: Log file $LOG_FILE has been modified!"
    echo "Previous hash: $PREVIOUS_HASH"
    echo "Current hash: $CURRENT_HASH"
    
    # ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
    curl -X POST -H 'Content-Type: application/json' \
      -d '{"text":"Log tampering detected in '"$LOG_FILE"'"}' \
      $SLACK_WEBHOOK_URL
  fi
fi

# ç¾åœ¨ã®ãƒãƒƒã‚·ãƒ¥ä¿å­˜
echo "$CURRENT_HASH" > "$HASH_FILE"
EOF

chmod +x log-integrity-check.sh

# å®šæœŸå®Ÿè¡Œè¨­å®š
(crontab -l 2>/dev/null; echo "*/5 * * * * /path/to/log-integrity-check.sh /var/log/audit/audit.log") | crontab -
```

### å•é¡Œ93 (1ç‚¹)
ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šã®æ§‹æˆãƒ‰ãƒªãƒ•ãƒˆæ¤œçŸ¥ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
# è¨­å®šãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ä½œæˆ
cat << 'EOF' > security-baseline.sh
#!/bin/bash

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å–å¾—
cat << BASELINE > /tmp/security-baseline.json
{
  "kubectl_config": {
    "anonymous_auth": false,
    "audit_logging": true,
    "rbac_enabled": true
  },
  "pod_security": {
    "pod_security_policy_enabled": true,
    "network_policy_enabled": true
  },
  "etcd": {
    "encryption_enabled": true,
    "tls_enabled": true
  }
}
BASELINE

# ç¾åœ¨ã®è¨­å®šå–å¾—ãƒ»æ¯”è¼ƒ
CURRENT_CONFIG=$(kubectl get configmap kube-system/cluster-info -o jsonpath='{.data.kubeconfig}')
API_SERVER_ARGS=$(ps aux | grep kube-apiserver | grep -o -- '--[^=]*=[^ ]*')

# è¨­å®šå·®åˆ†ãƒã‚§ãƒƒã‚¯
if ! echo "$API_SERVER_ARGS" | grep -q "anonymous-auth=false"; then
  echo "DRIFT: Anonymous auth not disabled"
fi

if ! echo "$API_SERVER_ARGS" | grep -q "audit-log-path"; then
  echo "DRIFT: Audit logging not configured"
fi

# PSPç¢ºèª
if ! kubectl get psp &>/dev/null; then
  echo "DRIFT: Pod Security Policy not enabled"
fi
EOF

chmod +x security-baseline.sh
```

### å•é¡Œ94 (1ç‚¹)
ã‚³ãƒ³ãƒ†ãƒŠã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã®æ¤œçŸ¥ãƒ«ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat >> /etc/falco/falco_rules.local.yaml << EOF
- rule: Container Escape Attempt
  desc: Detect potential container escape attempts
  condition: >
    spawned_process and
    container and
    (proc.name in (docker, runc, containerd, ctr) or
     proc.cmdline contains "mount --bind" or
     proc.cmdline contains "/proc/1/root" or
     proc.cmdline contains "nsenter" or
     proc.cmdline contains "unshare")
  output: >
    Container escape attempt detected (user=%user.name container_id=%container.id 
    proc=%proc.name cmdline=%proc.cmdline)
  priority: CRITICAL
  tags: [container_escape, privilege_escalation]

- rule: Host Mount Access
  desc: Detect access to host filesystem from container
  condition: >
    open_read and
    container and
    fd.name startswith /host and
    not proc.name in (systemd, kubelet)
  output: >
    Host filesystem access from container (user=%user.name container_id=%container.id 
    file=%fd.name proc=%proc.name)
  priority: HIGH
  tags: [container_escape, host_access]
EOF

# Falcoå†èµ·å‹•
systemctl restart falco
```

### å•é¡Œ95 (1ç‚¹)
ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒªã‚·ãƒ¼ã®è‡ªå‹•æ›´æ–°ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << 'EOF' > policy-updater.sh
#!/bin/bash

POLICY_REPO="https://github.com/company/security-policies.git"
LOCAL_PATH="/tmp/security-policies"

# æœ€æ–°ãƒãƒªã‚·ãƒ¼å–å¾—
git clone $POLICY_REPO $LOCAL_PATH || git -C $LOCAL_PATH pull

# NetworkPolicyæ›´æ–°
for policy in $LOCAL_PATH/network-policies/*.yaml; do
  kubectl apply -f "$policy"
done

# PodSecurityPolicyæ›´æ–°
for policy in $LOCAL_PATH/pod-security-policies/*.yaml; do
  kubectl apply -f "$policy"
done

# RBACæ›´æ–°
for policy in $LOCAL_PATH/rbac/*.yaml; do
  kubectl apply -f "$policy"
done

# é©ç”¨ç¢ºèª
kubectl get networkpolicy -A
kubectl get psp
kubectl get clusterrole | grep security

echo "Security policies updated successfully"
EOF

chmod +x policy-updater.sh

# å®šæœŸå®Ÿè¡Œè¨­å®š
(crontab -l 2>/dev/null; echo "0 2 * * * /path/to/policy-updater.sh") | crontab -
```

### å•é¡Œ96 (1ç‚¹)
ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ™ãƒ³ãƒˆã®çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆã‚’è‡ªå‹•ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << 'EOF' > security-report.sh
#!/bin/bash

REPORT_DATE=$(date +%Y-%m-%d)
REPORT_FILE="/tmp/security-report-$REPORT_DATE.html"

cat << REPORT > $REPORT_FILE
<!DOCTYPE html>
<html>
<head>
    <title>Security Report - $REPORT_DATE</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        table { border-collapse: collapse; width: 100%; }
        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
        th { background-color: #f2f2f2; }
        .critical { color: red; font-weight: bold; }
        .warning { color: orange; }
        .info { color: blue; }
    </style>
</head>
<body>
    <h1>Daily Security Report - $REPORT_DATE</h1>
    
    <h2>Summary</h2>
    <table>
        <tr><th>Metric</th><th>Count</th><th>Status</th></tr>
        <tr><td>Failed Logins</td><td>$(grep "authentication failure" /var/log/audit/audit.log | wc -l)</td><td class="warning">Review</td></tr>
        <tr><td>PSP Violations</td><td>$(kubectl get events -A | grep "PodSecurityPolicy" | wc -l)</td><td class="info">Normal</td></tr>
        <tr><td>Privilege Escalations</td><td>$(grep "sudo" /var/log/audit/audit.log | wc -l)</td><td class="critical">Alert</td></tr>
    </table>
    
    <h2>Top Security Events</h2>
    <pre>
$(tail -20 /var/log/falco/falco.log | grep -E "(WARNING|ERROR|CRITICAL)")
    </pre>
    
    <h2>Recommendations</h2>
    <ul>
        <li>Review failed login attempts for potential brute force attacks</li>
        <li>Investigate privilege escalation events</li>
        <li>Update security policies if necessary</li>
    </ul>
</body>
</html>
REPORT

# ãƒ¬ãƒãƒ¼ãƒˆé€ä¿¡
mail -s "Security Report - $REPORT_DATE" -a "Content-Type: text/html" \
  security-team@company.com < $REPORT_FILE

echo "Security report generated: $REPORT_FILE"
EOF

chmod +x security-report.sh

# æ¯æ—¥ã®è‡ªå‹•å®Ÿè¡Œ
(crontab -l 2>/dev/null; echo "0 8 * * * /path/to/security-report.sh") | crontab -
```

### å•é¡Œ97 (1ç‚¹)
ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã®è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³çµæœã‚’Slackã«é€šçŸ¥ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << 'EOF' > vulnerability-notifier.sh
#!/bin/bash

IMAGE=$1
SLACK_WEBHOOK=$2

if [ -z "$IMAGE" ] || [ -z "$SLACK_WEBHOOK" ]; then
  echo "Usage: $0 <image> <slack_webhook>"
  exit 1
fi

# Trivyã‚¹ã‚­ãƒ£ãƒ³å®Ÿè¡Œ
SCAN_RESULT=$(trivy image --format json --quiet $IMAGE)
HIGH_COUNT=$(echo "$SCAN_RESULT" | jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "HIGH")] | length')
CRITICAL_COUNT=$(echo "$SCAN_RESULT" | jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "CRITICAL")] | length')

# Slacké€šçŸ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰
if [ $CRITICAL_COUNT -gt 0 ] || [ $HIGH_COUNT -gt 5 ]; then
  SEVERITY="ğŸš¨ CRITICAL"
  COLOR="danger"
elif [ $HIGH_COUNT -gt 0 ]; then
  SEVERITY="âš ï¸ WARNING"
  COLOR="warning"
else
  SEVERITY="âœ… LOW RISK"
  COLOR="good"
fi

# Slacké€šçŸ¥é€ä¿¡
curl -X POST -H 'Content-Type: application/json' \
  -d '{
    "attachments": [
      {
        "color": "'$COLOR'",
        "title": "Image Vulnerability Scan: '$IMAGE'",
        "fields": [
          {
            "title": "Severity",
            "value": "'$SEVERITY'",
            "short": true
          },
          {
            "title": "Critical",
            "value": "'$CRITICAL_COUNT'",
            "short": true
          },
          {
            "title": "High",
            "value": "'$HIGH_COUNT'",
            "short": true
          }
        ]
      }
    ]
  }' \
  $SLACK_WEBHOOK

echo "Vulnerability scan notification sent for $IMAGE"
EOF

chmod +x vulnerability-notifier.sh
```

### å•é¡Œ98 (1ç‚¹)
Kubernetesãƒªã‚½ãƒ¼ã‚¹ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šã‚’ç›£æŸ»ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << 'EOF' > k8s-security-audit.sh
#!/bin/bash

echo "=== Kubernetes Security Audit ==="

# 1. Pod Security Contextç¢ºèª
echo "Checking Pod Security Contexts..."
kubectl get pods -A -o jsonpath='{range .items[*]}{.metadata.namespace}/{.metadata.name}: {.spec.securityContext}{"\n"}{end}' | grep -v "runAsNonRoot:true"

# 2. Service Accountç¢ºèª
echo "Checking Service Accounts..."
kubectl get sa -A -o jsonpath='{range .items[*]}{.metadata.namespace}/{.metadata.name}: {.automountServiceAccountToken}{"\n"}{end}' | grep -v "false"

# 3. Network Policyç¢ºèª
echo "Checking Network Policies..."
NAMESPACES=$(kubectl get ns -o name | cut -d'/' -f2)
for ns in $NAMESPACES; do
  NP_COUNT=$(kubectl get networkpolicy -n $ns --no-headers 2>/dev/null | wc -l)
  if [ $NP_COUNT -eq 0 ]; then
    echo "âš ï¸ No Network Policy in namespace: $ns"
  fi
done

# 4. RBACç¢ºèª
echo "Checking RBAC..."
kubectl get clusterrolebinding -o jsonpath='{range .items[*]}{.metadata.name}: {.subjects[*].name}{"\n"}{end}' | grep -E "(system:anonymous|system:unauthenticated)"

# 5. Secretæš—å·åŒ–ç¢ºèª
echo "Checking Secret encryption..."
kubectl get secrets -A -o jsonpath='{range .items[*]}{.metadata.namespace}/{.metadata.name}{"\n"}{end}' | head -5

echo "=== Audit Complete ==="
EOF

chmod +x k8s-security-audit.sh
```

### å•é¡Œ99 (1ç‚¹)
ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚³ã‚¢ã‚’è‡ªå‹•è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << 'EOF' > security-benchmark.sh
#!/bin/bash

# CIS Kubernetes Benchmarkç°¡æ˜“ãƒã‚§ãƒƒã‚¯
TOTAL_CHECKS=10
PASSED_CHECKS=0

echo "=== CIS Kubernetes Benchmark Check ==="

# 1. API Server anonymous auth
if kubectl get configmap -n kube-system cluster-info -o yaml | grep -q "anonymous-auth=false"; then
  echo "âœ… 1.2.1 Anonymous auth disabled"
  ((PASSED_CHECKS++))
else
  echo "âŒ 1.2.1 Anonymous auth not disabled"
fi

# 2. kubelet anonymous auth
if [ -f /var/lib/kubelet/config.yaml ] && grep -q "enabled: false" /var/lib/kubelet/config.yaml; then
  echo "âœ… 4.2.1 Kubelet anonymous auth disabled"
  ((PASSED_CHECKS++))
else
  echo "âŒ 4.2.1 Kubelet anonymous auth not disabled"
fi

# 3. etcd encryption
if kubectl get secrets -A &>/dev/null; then
  echo "âœ… 1.2.33 etcd encryption at rest enabled"
  ((PASSED_CHECKS++))
else
  echo "âŒ 1.2.33 etcd encryption at rest not verified"
fi

# 4. Audit logging
if ps aux | grep kube-apiserver | grep -q "audit-log-path"; then
  echo "âœ… 1.2.22 Audit logging enabled"
  ((PASSED_CHECKS++))
else
  echo "âŒ 1.2.22 Audit logging not enabled"
fi

# 5. Pod Security Policy
if kubectl get psp &>/dev/null; then
  echo "âœ… 5.2.1 Pod Security Policy enabled"
  ((PASSED_CHECKS++))
else
  echo "âŒ 5.2.1 Pod Security Policy not enabled"
fi

# 6. Network Policy
if kubectl get networkpolicy -A --no-headers | wc -l | grep -q "^[1-9]"; then
  echo "âœ… 5.3.1 Network Policy configured"
  ((PASSED_CHECKS++))
else
  echo "âŒ 5.3.1 Network Policy not configured"
fi

# 7. RBAC enabled
if kubectl auth can-i --list &>/dev/null; then
  echo "âœ… 5.1.1 RBAC enabled"
  ((PASSED_CHECKS++))
else
  echo "âŒ 5.1.1 RBAC not verified"
fi

# 8. ServiceAccount auto mount disabled
SA_COUNT=$(kubectl get sa -A -o jsonpath='{.items[*].automountServiceAccountToken}' | tr ' ' '\n' | grep -c false)
if [ $SA_COUNT -gt 0 ]; then
  echo "âœ… 5.1.5 ServiceAccount auto mount controlled"
  ((PASSED_CHECKS++))
else
  echo "âŒ 5.1.5 ServiceAccount auto mount not controlled"
fi

# 9. Container security contexts
SECURE_PODS=$(kubectl get pods -A -o jsonpath='{.items[*].spec.securityContext.runAsNonRoot}' | tr ' ' '\n' | grep -c true)
if [ $SECURE_PODS -gt 0 ]; then
  echo "âœ… 5.7.2 Containers run as non-root"
  ((PASSED_CHECKS++))
else
  echo "âŒ 5.7.2 Containers may run as root"
fi

# 10. Secrets encryption
if kubectl get secret -n kube-system | grep -q encryption; then
  echo "âœ… Secrets properly encrypted"
  ((PASSED_CHECKS++))
else
  echo "âŒ Secrets encryption not verified"
fi

# ã‚¹ã‚³ã‚¢è¨ˆç®—
SCORE=$((PASSED_CHECKS * 100 / TOTAL_CHECKS))
echo "=== Benchmark Score: $SCORE% ($PASSED_CHECKS/$TOTAL_CHECKS) ==="

if [ $SCORE -ge 80 ]; then
  echo "ğŸ‰ Excellent security posture"
elif [ $SCORE -ge 60 ]; then
  echo "âš ï¸ Good security posture, room for improvement"
else
  echo "ğŸš¨ Poor security posture, immediate action required"
fi
EOF

chmod +x security-benchmark.sh
```

### å•é¡Œ100 (1ç‚¹)
æœ€çµ‚çš„ãªã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
```bash
cat << 'EOF' > final-security-assessment.sh
#!/bin/bash

OUTPUT_FILE="/tmp/final-security-assessment-$(date +%Y%m%d).json"

cat << ASSESSMENT > $OUTPUT_FILE
{
  "assessment_date": "$(date -Iseconds)",
  "cluster_info": {
    "cluster_version": "$(kubectl version --short --client)",
    "node_count": $(kubectl get nodes --no-headers | wc -l),
    "namespace_count": $(kubectl get ns --no-headers | wc -l)
  },
  "security_status": {
    "authentication": {
      "anonymous_auth_disabled": $(ps aux | grep kube-apiserver | grep -q "anonymous-auth=false" && echo true || echo false),
      "rbac_enabled": $(kubectl auth can-i --list &>/dev/null && echo true || echo false)
    },
    "authorization": {
      "pod_security_policy": $(kubectl get psp &>/dev/null && echo true || echo false),
      "network_policy_count": $(kubectl get networkpolicy -A --no-headers | wc -l)
    },
    "encryption": {
      "etcd_encryption": $(kubectl get secrets -A &>/dev/null && echo true || echo false),
      "tls_enabled": true
    },
    "monitoring": {
      "audit_logging": $(ps aux | grep kube-apiserver | grep -q "audit-log-path" && echo true || echo false),
      "falco_installed": $(systemctl is-active falco &>/dev/null && echo true || echo false)
    }
  },
  "compliance_score": {
    "cis_benchmark": "$(./security-benchmark.sh | grep 'Benchmark Score' | grep -o '[0-9]*')",
    "security_grade": "$([ $(./security-benchmark.sh | grep 'Benchmark Score' | grep -o '[0-9]*') -ge 80 ] && echo 'A' || echo 'B')"
  },
  "recommendations": [
    "Enable Pod Security Standards",
    "Implement comprehensive Network Policies",
    "Configure Falco for runtime security",
    "Set up centralized logging with encryption",
    "Regular security policy updates"
  ],
  "next_assessment": "$(date -d '+30 days' -Iseconds)"
}
ASSESSMENT

echo "Final security assessment saved to: $OUTPUT_FILE"

# çµæœã‚’Slackã«é€ä¿¡
SCORE=$(jq -r '.compliance_score.cis_benchmark' $OUTPUT_FILE)
GRADE=$(jq -r '.compliance_score.security_grade' $OUTPUT_FILE)

curl -X POST -H 'Content-Type: application/json' \
  -d '{
    "text": "Security Assessment Complete",
    "attachments": [
      {
        "color": "'$([ "$GRADE" = "A" ] && echo "good" || echo "warning")'",
        "fields": [
          {
            "title": "Compliance Score",
            "value": "'$SCORE'%",
            "short": true
          },
          {
            "title": "Security Grade",
            "value": "'$GRADE'",
            "short": true
          }
        ]
      }
    ]
  }' \
  $SLACK_WEBHOOK_URL

echo "Assessment notification sent"
EOF

chmod +x final-security-assessment.sh
```

---

## ğŸ“Š æ¡ç‚¹åŸºæº–

### Domainåˆ¥é…ç‚¹
- **Cluster Setup (10%)**: 10ç‚¹
- **Cluster Hardening (15%)**: 15ç‚¹
- **System Hardening (15%)**: 15ç‚¹
- **Minimize Microservice Vulnerabilities (20%)**: 20ç‚¹
- **Supply Chain Security (20%)**: 20ç‚¹
- **Monitoring, Logging and Runtime Security (20%)**: 20ç‚¹

### ç·åˆè©•ä¾¡
- **90-100ç‚¹**: Excellent - å®Ÿå‹™ã§ååˆ†ã«æ´»ç”¨ã§ãã‚‹ãƒ¬ãƒ™ãƒ«
- **80-89ç‚¹**: Good - åŸºæœ¬çš„ãªã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å®Ÿè£…ãŒå¯èƒ½
- **67-79ç‚¹**: Pass - è©¦é¨“åˆæ ¼ãƒ¬ãƒ™ãƒ«
- **66ç‚¹ä»¥ä¸‹**: Fail - è¿½åŠ å­¦ç¿’ãŒå¿…è¦

## ğŸ¯ è©¦é¨“ã®ãƒã‚¤ãƒ³ãƒˆ

### æ™‚é–“é…åˆ†ã®ç›®å®‰
- Domain 1 (10å•): 12åˆ†
- Domain 2 (15å•): 18åˆ†
- Domain 3 (15å•): 18åˆ†
- Domain 4 (20å•): 24åˆ†
- Domain 5 (20å•): 24åˆ†
- Domain 6 (20å•): 24åˆ†

### é‡è¦ãªã‚³ãƒãƒ³ãƒ‰
```bash
# ã‚¨ã‚¤ãƒªã‚¢ã‚¹è¨­å®š
alias k=kubectl
export do='--dry-run=client -o yaml'

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç¢ºèª
k auth can-i --list --as=system:serviceaccount:default:sa
k get networkpolicy -A
k get podsecuritypolicy
```

### ã‚ˆãã‚ã‚‹é–“é•ã„
1. YAML ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼
2. åå‰ç©ºé–“ã®æŒ‡å®šå¿˜ã‚Œ
3. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®è¨­å®šãƒŸã‚¹
4. RBACæ¨©é™ã®éå‰°ä»˜ä¸
5. Network Policyã®è«–ç†ã‚¨ãƒ©ãƒ¼

---

**é‡è¦**: ã“ã®ç·´ç¿’å•é¡Œã‚’åˆ¶é™æ™‚é–“å†…ã§è§£ã‘ã‚‹ã‚ˆã†ã«ãªã‚‹ã“ã¨ãŒã€CKSè©¦é¨“åˆæ ¼ã®é‡è¦ãªæŒ‡æ¨™ã§ã™ã€‚å®Ÿéš›ã®è©¦é¨“ç’°å¢ƒã«è¿‘ã„æ¡ä»¶ã§ç·´ç¿’ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚