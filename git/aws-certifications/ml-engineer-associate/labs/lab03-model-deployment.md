# Lab 3: ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

## ğŸ¯ å­¦ç¿’ç›®æ¨™

ã“ã®ãƒ©ãƒœã§ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã«é–¢ã™ã‚‹å®Ÿè·µçš„ãªã‚¹ã‚­ãƒ«ã‚’ç¿’å¾—ã—ã¾ã™ï¼š

- SageMaker Endpoint ã§ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–
- ãƒãƒƒãƒå¤‰æ›ã«ã‚ˆã‚‹å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†
- ãƒãƒ«ãƒãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ§‹ç¯‰
- A/B ãƒ†ã‚¹ãƒˆã¨ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ
- Auto Scaling ã¨ã‚³ã‚¹ãƒˆæœ€é©åŒ–

## ğŸ“‹ å‰ææ¡ä»¶

- AWS CLI ãŒè¨­å®šæ¸ˆã¿
- SageMaker å®Ÿè¡Œãƒ­ãƒ¼ãƒ«ã®ä½œæˆ
- [Lab 2: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–](./lab02-model-training.md) ã®å®Œäº†æ¨å¥¨

## ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆç’°å¢ƒ                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Model     â”‚    â”‚   Batch     â”‚    â”‚   Multi     â”‚     â”‚
â”‚  â”‚   Registry  â”‚    â”‚ Transform   â”‚    â”‚   Model     â”‚     â”‚
â”‚  â”‚             â”‚    â”‚             â”‚    â”‚  Endpoint   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚        â”‚                  â”‚                  â”‚             â”‚
â”‚        â–¼                  â–¼                  â–¼             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                Real-time Endpoint                      â”‚ â”‚
â”‚  â”‚              Auto Scaling & Load Balancing             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚        â”‚                       â”‚                             â”‚
â”‚        â–¼                       â–¼                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚   A/B Test  â”‚         â”‚   Canary    â”‚                     â”‚
â”‚  â”‚  Variants   â”‚         â”‚   Deploy    â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Step 1: Real-time Endpoint ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

### 1.1 å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™

```python
import boto3
import sagemaker
from sagemaker import get_execution_role
from sagemaker.sklearn.model import SKLearnModel
from sagemaker.predictor import Predictor

# SageMaker ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®š
sagemaker_session = sagemaker.Session()
role = get_execution_role()
region = boto3.Session().region_name

# å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã®S3ãƒ‘ã‚¹
model_artifacts = 's3://your-bucket/sagemaker-models/model.tar.gz'

print(f"Region: {region}")
print(f"Role: {role}")
print(f"Model artifacts: {model_artifacts}")
```

### 1.2 æ¨è«–ã‚³ãƒ¼ãƒ‰ï¼ˆinference.pyï¼‰ã®ä½œæˆ

```python
# inference.py - ã‚«ã‚¹ã‚¿ãƒ æ¨è«–ãƒ­ã‚¸ãƒƒã‚¯
import json
import joblib
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier

def model_fn(model_dir):
    """ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
    try:
        model = joblib.load(f"{model_dir}/model.pkl")
        return model
    except Exception as e:
        raise Exception(f"Failed to load model: {str(e)}")

def input_fn(request_body, request_content_type):
    """å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†"""
    if request_content_type == 'application/json':
        data = json.loads(request_body)
        
        # DataFrame ã«å¤‰æ›
        if isinstance(data, dict):
            # å˜ä¸€ã®äºˆæ¸¬ã®å ´åˆ
            df = pd.DataFrame([data])
        else:
            # ãƒãƒƒãƒäºˆæ¸¬ã®å ´åˆ
            df = pd.DataFrame(data)
        
        return df
    
    elif request_content_type == 'text/csv':
        df = pd.read_csv(StringIO(request_body))
        return df
    
    else:
        raise ValueError(f"Unsupported content type: {request_content_type}")

def predict_fn(input_data, model):
    """äºˆæ¸¬å®Ÿè¡Œ"""
    try:
        # äºˆæ¸¬ç¢ºç‡ã‚’å–å¾—
        prediction_proba = model.predict_proba(input_data)
        
        # äºˆæ¸¬ã‚¯ãƒ©ã‚¹ã‚’å–å¾—
        prediction = model.predict(input_data)
        
        # çµæœã‚’ã¾ã¨ã‚ã‚‹
        result = {
            'predictions': prediction.tolist(),
            'probabilities': prediction_proba.tolist(),
            'feature_importance': model.feature_importances_.tolist() if hasattr(model, 'feature_importances_') else None
        }
        
        return result
        
    except Exception as e:
        raise Exception(f"Prediction failed: {str(e)}")

def output_fn(prediction, content_type):
    """å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã®å¾Œå‡¦ç†"""
    if content_type == 'application/json':
        return json.dumps(prediction)
    else:
        raise ValueError(f"Unsupported content type: {content_type}")
```

### 1.3 ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

```python
from sagemaker.sklearn.model import SKLearnModel

# SKLearn ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©
sklearn_model = SKLearnModel(
    model_data=model_artifacts,
    role=role,
    entry_point='inference.py',
    framework_version='0.23-1',
    py_version='py3',
    name='ml-model-deployment'
)

# Real-time Endpoint ã®ãƒ‡ãƒ—ãƒ­ã‚¤
predictor = sklearn_model.deploy(
    initial_instance_count=1,
    instance_type='ml.m5.large',
    endpoint_name='ml-realtime-endpoint',
    wait=True
)

print(f"Endpoint deployed: {predictor.endpoint_name}")
```

### 1.4 æ¨è«–ãƒ†ã‚¹ãƒˆ

```python
# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
test_data = {
    'feature_1': 5.1,
    'feature_2': 3.5,
    'feature_3': 1.4,
    'feature_4': 0.2
}

# æ¨è«–å®Ÿè¡Œ
result = predictor.predict(test_data)
print(f"Prediction result: {result}")

# ãƒãƒƒãƒæ¨è«–ãƒ†ã‚¹ãƒˆ
batch_data = [
    {'feature_1': 5.1, 'feature_2': 3.5, 'feature_3': 1.4, 'feature_4': 0.2},
    {'feature_1': 4.9, 'feature_2': 3.0, 'feature_3': 1.4, 'feature_4': 0.2},
    {'feature_1': 4.7, 'feature_2': 3.2, 'feature_3': 1.3, 'feature_4': 0.2}
]

batch_result = predictor.predict(batch_data)
print(f"Batch prediction result: {batch_result}")
```

## ğŸ“Š Step 2: ãƒãƒƒãƒå¤‰æ›ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿å‡¦ç†

### 2.1 ãƒãƒƒãƒå¤‰æ›ã‚¸ãƒ§ãƒ–ã®è¨­å®š

```python
from sagemaker.transformer import Transformer

# Transformer ã®ä½œæˆ
transformer = sklearn_model.transformer(
    instance_count=1,
    instance_type='ml.m5.large',
    output_path='s3://your-bucket/batch-transform-output/',
    accept='application/json',
    assemble_with='Line'
)

# ãƒãƒƒãƒå¤‰æ›ã®å®Ÿè¡Œ
input_data = 's3://your-bucket/batch-input/data.csv'

transformer.transform(
    data=input_data,
    content_type='text/csv',
    split_type='Line',
    job_name='batch-transform-job'
)

# ã‚¸ãƒ§ãƒ–ã®ç›£è¦–
transformer.wait()
print(f"Batch transform completed: {transformer.output_path}")
```

### 2.2 å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®æœ€é©åŒ–

```python
# å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”¨ã®è¨­å®š
large_transformer = sklearn_model.transformer(
    instance_count=3,  # è¤‡æ•°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§ä¸¦åˆ—å‡¦ç†
    instance_type='ml.m5.2xlarge',
    max_payload=100,  # MBå˜ä½
    max_concurrent_transforms=3,
    output_path='s3://your-bucket/large-batch-output/',
    accept='application/json'
)

# ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²å‡¦ç†
large_input_data = 's3://your-bucket/large-dataset/'

large_transformer.transform(
    data=large_input_data,
    content_type='text/csv',
    split_type='Line',
    job_name='large-batch-transform'
)
```

## ğŸ”„ Step 3: ãƒãƒ«ãƒãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

### 3.1 ãƒãƒ«ãƒãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ§‹ç¯‰

```python
from sagemaker.multidatamodel import MultiDataModel

# ãƒãƒ«ãƒãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆç”¨ã®ãƒ¢ãƒ‡ãƒ«æº–å‚™
model_data_prefix = 's3://your-bucket/multi-models/'

# è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’é…ç½®
models = {
    'model-v1': 's3://your-bucket/models/model-v1.tar.gz',
    'model-v2': 's3://your-bucket/models/model-v2.tar.gz',
    'model-v3': 's3://your-bucket/models/model-v3.tar.gz'
}

# MultiDataModel ã®ä½œæˆ
multi_model = MultiDataModel(
    name='multi-model-endpoint',
    model_data_prefix=model_data_prefix,
    model=sklearn_model,
    sagemaker_session=sagemaker_session
)

# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ‡ãƒ—ãƒ­ã‚¤
multi_predictor = multi_model.deploy(
    initial_instance_count=1,
    instance_type='ml.m5.large',
    endpoint_name='multi-model-endpoint'
)
```

### 3.2 å‹•çš„ãƒ¢ãƒ‡ãƒ«è¿½åŠ ãƒ»å‰Šé™¤

```python
# æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã®è¿½åŠ 
multi_model.add_model(
    model_data_source='s3://your-bucket/models/model-v4.tar.gz',
    model_data_path='model-v4.tar.gz'
)

# ãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆè¡¨ç¤º
models_list = multi_model.list_models()
print(f"Available models: {models_list}")

# ç‰¹å®šãƒ¢ãƒ‡ãƒ«ã§ã®æ¨è«–
test_data = {'feature_1': 5.1, 'feature_2': 3.5}

# model-v2 ã‚’ä½¿ç”¨ã—ã¦æ¨è«–
result_v2 = multi_predictor.predict(
    data=test_data,
    target_model='model-v2.tar.gz'
)
print(f"Model v2 result: {result_v2}")

# ãƒ¢ãƒ‡ãƒ«ã®å‰Šé™¤
multi_model.delete_model('model-v1.tar.gz')
```

## âš–ï¸ Step 4: A/B ãƒ†ã‚¹ãƒˆã¨ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

### 4.1 A/B ãƒ†ã‚¹ãƒˆç’°å¢ƒã®æ§‹ç¯‰

```python
from sagemaker.model import Model

# ãƒ¢ãƒ‡ãƒ«Aï¼ˆæ—¢å­˜ï¼‰ã¨ãƒ¢ãƒ‡ãƒ«Bï¼ˆæ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰ã®æº–å‚™
model_a = SKLearnModel(
    model_data='s3://your-bucket/models/model-a.tar.gz',
    role=role,
    entry_point='inference.py',
    framework_version='0.23-1',
    name='model-a'
)

model_b = SKLearnModel(
    model_data='s3://your-bucket/models/model-b.tar.gz',
    role=role,
    entry_point='inference.py',
    framework_version='0.23-1',
    name='model-b'
)

# Production Variant ã®è¨­å®š
from sagemaker.model import Model

# A/B ãƒ†ã‚¹ãƒˆç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè¨­å®š
ab_test_config = [
    {
        'VariantName': 'model-a-variant',
        'ModelName': model_a.name,
        'InitialInstanceCount': 1,
        'InstanceType': 'ml.m5.large',
        'InitialVariantWeight': 70  # 70%ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯
    },
    {
        'VariantName': 'model-b-variant',
        'ModelName': model_b.name,
        'InitialInstanceCount': 1,
        'InstanceType': 'ml.m5.large',
        'InitialVariantWeight': 30  # 30%ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯
    }
]

# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆä½œæˆï¼ˆä½ãƒ¬ãƒ™ãƒ«APIä½¿ç”¨ï¼‰
sagemaker_client = boto3.client('sagemaker')

endpoint_config_name = 'ab-test-endpoint-config'
endpoint_name = 'ab-test-endpoint'

# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè¨­å®šã®ä½œæˆ
sagemaker_client.create_endpoint_config(
    EndpointConfigName=endpoint_config_name,
    ProductionVariants=ab_test_config
)

# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆ
sagemaker_client.create_endpoint(
    EndpointName=endpoint_name,
    EndpointConfigName=endpoint_config_name
)
```

### 4.2 ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯é…åˆ†ã®å‹•çš„å¤‰æ›´

```python
# ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯é…åˆ†ã®æ›´æ–°
def update_traffic_distribution(endpoint_name, variant_weights):
    """
    ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯é…åˆ†ã‚’æ›´æ–°
    
    Args:
        endpoint_name: ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå
        variant_weights: ãƒãƒªã‚¢ãƒ³ãƒˆé‡ã¿ {'variant_name': weight}
    """
    sagemaker_client = boto3.client('sagemaker')
    
    # ç¾åœ¨ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè¨­å®šã‚’å–å¾—
    response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)
    
    # æ–°ã—ã„ãƒãƒªã‚¢ãƒ³ãƒˆè¨­å®š
    updated_variants = []
    for variant in response['ProductionVariants']:
        variant_name = variant['VariantName']
        if variant_name in variant_weights:
            variant['CurrentWeight'] = variant_weights[variant_name]
        updated_variants.append({
            'VariantName': variant_name,
            'CurrentWeight': variant.get('CurrentWeight', 0)
        })
    
    # ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè¨­å®šã‚’æ›´æ–°
    sagemaker_client.update_endpoint_weights_and_capacities(
        EndpointName=endpoint_name,
        DesiredWeightsAndCapacities=updated_variants
    )
    
    print(f"Traffic distribution updated for {endpoint_name}")

# ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆï¼ˆæ®µéšçš„ãªé…åˆ†å¤‰æ›´ï¼‰
# Stage 1: 10% to new model
update_traffic_distribution(endpoint_name, {
    'model-a-variant': 90,
    'model-b-variant': 10
})

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–å¾Œã€Stage 2: 50% to new model
update_traffic_distribution(endpoint_name, {
    'model-a-variant': 50,
    'model-b-variant': 50
})

# æœ€çµ‚çš„ã«æ–°ãƒ¢ãƒ‡ãƒ«ã«å®Œå…¨ç§»è¡Œ
update_traffic_distribution(endpoint_name, {
    'model-a-variant': 0,
    'model-b-variant': 100
})
```

## ğŸ“ˆ Step 5: Auto Scaling ã¨ã‚³ã‚¹ãƒˆæœ€é©åŒ–

### 5.1 Auto Scaling ã®è¨­å®š

```python
import boto3

# Application Auto Scaling ã®è¨­å®š
autoscaling_client = boto3.client('application-autoscaling')

# Scalable Target ã®ç™»éŒ²
resource_id = f"endpoint/{endpoint_name}/variant/model-variant"

autoscaling_client.register_scalable_target(
    ServiceNamespace='sagemaker',
    ResourceId=resource_id,
    ScalableDimension='sagemaker:variant:DesiredInstanceCount',
    MinCapacity=1,
    MaxCapacity=10,
    RoleArn='arn:aws:iam::account:role/application-autoscaling-sagemaker-role'
)

# ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒãƒªã‚·ãƒ¼ã®ä½œæˆ
policy_name = 'sagemaker-scaling-policy'

autoscaling_client.put_scaling_policy(
    PolicyName=policy_name,
    ServiceNamespace='sagemaker',
    ResourceId=resource_id,
    ScalableDimension='sagemaker:variant:DesiredInstanceCount',
    PolicyType='TargetTrackingScaling',
    TargetTrackingScalingPolicyConfiguration={
        'TargetValue': 70.0,  # 70% CPUä½¿ç”¨ç‡ã‚’ç›®æ¨™
        'PredefinedMetricSpecification': {
            'PredefinedMetricType': 'SageMakerVariantInvocationsPerInstance'
        },
        'ScaleOutCooldown': 300,  # 5åˆ†
        'ScaleInCooldown': 300
    }
)

print(f"Auto scaling configured for {endpoint_name}")
```

### 5.2 Serverless Inference ã®åˆ©ç”¨

```python
from sagemaker.serverless import ServerlessInferenceConfig

# Serverless è¨­å®š
serverless_config = ServerlessInferenceConfig(
    memory_size_in_mb=3008,  # æœ€å¤§6008MB
    max_concurrency=10       # æœ€å¤§åŒæ™‚å®Ÿè¡Œæ•°
)

# Serverless Endpoint ã®ãƒ‡ãƒ—ãƒ­ã‚¤
serverless_predictor = sklearn_model.deploy(
    serverless_inference_config=serverless_config,
    endpoint_name='serverless-ml-endpoint'
)

print(f"Serverless endpoint deployed: {serverless_predictor.endpoint_name}")

# Serverless ã§ã®æ¨è«–ãƒ†ã‚¹ãƒˆ
test_result = serverless_predictor.predict(test_data)
print(f"Serverless prediction: {test_result}")
```

### 5.3 ã‚³ã‚¹ãƒˆç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ

```python
import boto3

def setup_cost_monitoring(endpoint_name):
    """ã‚³ã‚¹ãƒˆç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆã®è¨­å®š"""
    
    cloudwatch = boto3.client('cloudwatch')
    
    # ã‚³ã‚¹ãƒˆã‚¢ãƒ©ãƒ¼ãƒ ã®ä½œæˆ
    cloudwatch.put_metric_alarm(
        AlarmName=f'{endpoint_name}-cost-alarm',
        ComparisonOperator='GreaterThanThreshold',
        EvaluationPeriods=1,
        MetricName='EstimatedCharges',
        Namespace='AWS/Billing',
        Period=86400,  # 1æ—¥
        Statistic='Maximum',
        Threshold=100.0,  # $100/æ—¥
        ActionsEnabled=True,
        AlarmActions=[
            'arn:aws:sns:region:account:cost-alarm-topic'
        ],
        AlarmDescription=f'Cost alarm for {endpoint_name}',
        Dimensions=[
            {
                'Name': 'Currency',
                'Value': 'USD'
            }
        ]
    )
    
    # æ¨è«–å›æ•°ã®ã‚¢ãƒ©ãƒ¼ãƒ 
    cloudwatch.put_metric_alarm(
        AlarmName=f'{endpoint_name}-invocation-alarm',
        ComparisonOperator='GreaterThanThreshold',
        EvaluationPeriods=2,
        MetricName='Invocations',
        Namespace='AWS/SageMaker',
        Period=300,
        Statistic='Sum',
        Threshold=1000.0,  # 5åˆ†é–“ã§1000å›ä»¥ä¸Š
        ActionsEnabled=True,
        AlarmActions=[
            'arn:aws:sns:region:account:invocation-alarm-topic'
        ],
        AlarmDescription=f'High invocation rate for {endpoint_name}',
        Dimensions=[
            {
                'Name': 'EndpointName',
                'Value': endpoint_name
            }
        ]
    )
    
    print(f"Cost monitoring configured for {endpoint_name}")

# ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°è¨­å®šã®å®Ÿè¡Œ
setup_cost_monitoring(endpoint_name)
```

## ğŸ” Step 6: ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨ãƒ­ã‚®ãƒ³ã‚°

### 6.1 CloudWatch ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ç›£è¦–

```python
def get_endpoint_metrics(endpoint_name, start_time, end_time):
    """ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—"""
    
    cloudwatch = boto3.client('cloudwatch')
    
    metrics = [
        'Invocations',
        'InvocationsPerInstance', 
        'ModelLatency',
        'OverheadLatency'
    ]
    
    results = {}
    
    for metric in metrics:
        response = cloudwatch.get_metric_statistics(
            Namespace='AWS/SageMaker',
            MetricName=metric,
            Dimensions=[
                {
                    'Name': 'EndpointName',
                    'Value': endpoint_name
                }
            ],
            StartTime=start_time,
            EndTime=end_time,
            Period=300,  # 5åˆ†é–“éš”
            Statistics=['Average', 'Maximum', 'Sum']
        )
        
        results[metric] = response['Datapoints']
    
    return results

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—ä¾‹
from datetime import datetime, timedelta

end_time = datetime.utcnow()
start_time = end_time - timedelta(hours=1)

metrics = get_endpoint_metrics(endpoint_name, start_time, end_time)
print(f"Endpoint metrics: {metrics}")
```

### 6.2 Data Capture ã®è¨­å®š

```python
from sagemaker.model_monitor import DataCaptureConfig

# Data Capture è¨­å®š
data_capture_config = DataCaptureConfig(
    enable_capture=True,
    sampling_percentage=100,  # 100%ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£
    destination_s3_uri='s3://your-bucket/data-capture/',
    capture_options=["REQUEST", "RESPONSE"]
)

# Data Capture æœ‰åŠ¹åŒ–ã§ã®ãƒ‡ãƒ—ãƒ­ã‚¤
predictor_with_capture = sklearn_model.deploy(
    initial_instance_count=1,
    instance_type='ml.m5.large',
    endpoint_name='ml-endpoint-with-capture',
    data_capture_config=data_capture_config
)

print(f"Endpoint with data capture deployed: {predictor_with_capture.endpoint_name}")
```

## ğŸ§¹ Step 7: ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

### 7.1 ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å‰Šé™¤

```python
# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å‰Šé™¤
predictor.delete_endpoint()
print(f"Endpoint {predictor.endpoint_name} deleted")

# ãƒãƒ«ãƒãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å‰Šé™¤
multi_predictor.delete_endpoint()
print(f"Multi-model endpoint {multi_predictor.endpoint_name} deleted")

# Serverless ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å‰Šé™¤
serverless_predictor.delete_endpoint()
print(f"Serverless endpoint {serverless_predictor.endpoint_name} deleted")
```

### 7.2 ãƒ¢ãƒ‡ãƒ«ã¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè¨­å®šã®å‰Šé™¤

```python
sagemaker_client = boto3.client('sagemaker')

# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè¨­å®šã®å‰Šé™¤
try:
    sagemaker_client.delete_endpoint_config(
        EndpointConfigName=endpoint_config_name
    )
    print(f"Endpoint config {endpoint_config_name} deleted")
except Exception as e:
    print(f"Error deleting endpoint config: {e}")

# ãƒ¢ãƒ‡ãƒ«ã®å‰Šé™¤
try:
    sagemaker_client.delete_model(ModelName=sklearn_model.name)
    print(f"Model {sklearn_model.name} deleted")
except Exception as e:
    print(f"Error deleting model: {e}")
```

## ğŸ’° ã‚³ã‚¹ãƒˆè¨ˆç®—

### æ¨å®šã‚³ã‚¹ãƒˆ
- **ml.m5.large ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹**: $0.115/æ™‚é–“
- **ãƒ‡ãƒ¼ã‚¿è»¢é€**: $0.09/GB
- **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: $0.023/GB/æœˆ

### 1æ™‚é–“ã®å®Ÿç¿’ã‚³ã‚¹ãƒˆ
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: $0.115
- ãƒãƒƒãƒå¤‰æ›: $0.115
- ãƒ‡ãƒ¼ã‚¿è»¢é€ãƒ»ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸: $0.05
- **åˆè¨ˆ**: ç´„ $0.28/æ™‚é–“

## ğŸ“š å­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ

### é‡è¦ãªæ¦‚å¿µ
1. **ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  vs ãƒãƒƒãƒ vs ãƒãƒ«ãƒãƒ¢ãƒ‡ãƒ«
2. **ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°**: Auto Scaling ã¨Serverless
3. **A/B ãƒ†ã‚¹ãƒˆ**: æ®µéšçš„ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ
4. **ç›£è¦–**: CloudWatch ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨Data Capture
5. **ã‚³ã‚¹ãƒˆæœ€é©åŒ–**: é©åˆ‡ãªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—é¸æŠ

### å®Ÿè·µçš„ãªã‚¹ã‚­ãƒ«
- ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ‡ãƒ—ãƒ­ã‚¤ã¨ç®¡ç†
- ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯é…åˆ†ã®åˆ¶å¾¡
- æ€§èƒ½ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
- ã‚³ã‚¹ãƒˆåŠ¹æœçš„ãªãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥

---

**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**: [Lab 4: MLOpsãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³](./lab04-mlops-pipeline.md) ã§ã¯ã€ç¶™ç¶šçš„ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆï¼ˆCI/CDï¼‰ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰ã‚’å­¦ç¿’ã—ã¾ã™ã€‚